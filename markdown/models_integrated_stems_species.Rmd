---
title: "Integrated model of stem density and and species composition"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)

library(rjags)
library(R2jags)

library(boral)
#library(ggboral)

library(dplyr)
library(ggplot2)
library(ggrepel)
library(latex2exp)
library(readxl)
library(stringr)
library(tidyr)

# local package
data(SITES, package = "RRGcommon")

# Random number seed
set.seed(42)

# Set this to TRUE to force re-fitting of models if
# cached objects exist. Set to FALSE to use cached outputs.
REFIT_MODELS <- FALSE

# Set this to TRUE to save graphs to file with the gg_pdf function (below).
SAVE_GRAPHS <- TRUE

# Default theme for graphs
theme_set( theme_bw() + theme(panel.grid = element_blank()))


# Load common functions
source(file = here("scripts", "common_functions.R"))

# Size class look-up table
data(SIZES, package = "RRGcommon")

```


## Model description

Here we construct two new models (denoted 3A and 3B) that follow the general form of model 3 (see `models_boral.Rmd`) to relate understorey species composition to flood history and tree stem density. With model 3 we provided mean stem density estimates (fitted by Bayesian bootstrap) to the model as data, but here we instead provide observed sub-plot tree counts and have the model estimate mean stem density and probability of occurrence for species simultaneously.

The two new models differ only in how flood history is represented. In model 3A, each 9ha plot has been assigned to one of three groups derived from a hierarchical classification of flood occurrence data from Landsat mapping. In model 3B, flood frequency for each 9ha plot is used as a continuous predictor.

The motivation for an integrated model is to account for within-plot variability in stem density. Estimating mean density per tree size class at each model iteration means that we are relating species probabilities of occurrence within a given plot to a *distribution* of mean stem density values, where the shape of the distribution reflects the variability over the 0.1ha sub-plot counts for the plot.

As a first step, we developed a separate JAGS model of stem density (see `model_subplot_stems_JAGS.Rmd`) to fit a negative binomial distribution to stems by size class by plot. In this document, the stem density model forms a sub-model that is connected to a species occurrence sub-model adapted from BORAL-generated JAGS code.

Because of the simultaneous MCMC sampling of both stem density means and species occurrence probabilities, information can flow in either direction between the two sub-models. In other words, the model's estimate of mean stem density for a particular tree size class and plot can be influenced by the patterns that it is discovering between species occurrence and that trees in that size class over all plots. As a consequence of this, inferences about the effects of tree density on understorey species are based on an integrated and consistent use of the available data.

In model 3 we used stochastic search variable selection (SSVS), implemented in BORAL as 'spike and slab' prior distributions, to allow the model to select a subset of tree size classes when modelling each individual understorey species. We then visualized the modelled effects of stem density on species occurrence using heatmap-style graphs of size class inclusion rates for each species. In the models developed here, we replace SSVS with Laplace (double exponential) prior distributions for species coefficients on size class densities. These priors provide 'adaptive shrinkage' (O'Hara and Sillanpää, 2009) of coefficient estimates towards zero, i.e. the data have to support a more substantial effect for thecoefficient value to move from zero than is the case with Normal priors. They thus serve a similar variable selection role to SSVS priors, but require less work in the MCMC sampling process and provide values that can be directly displayed in a heat-map style graph.


## Data

Response data is a matrix of species occurrences within 9ha experimental plots. The data for each plot are formed by pooling records from the three floristics quadrats located within the plot.

```{r}

DAT.occurrence.long <- load_from( here("data", "site_species_boral.RData") ) %>%
  
  mutate(siteplot = paste0(site, "-", plot9ha)) %>%
  
  distinct(site, plot9ha, siteplot, workingcode)

```


Coding, name and habitat information for species.

```{r}

SPECIES.info <- load_from( here("data", "species_info_boral.RData") )

```


Summary of species prevalence in sites, plots and quadrats.

```{r}

SPECIES.summary <- load_from( here("data", "species_summary_boral.RData") )

```


Flood history plot groupings.

```{r}

DAT.floodgroup <- load_from( here("data", "flood_group_boral.RData") )

```


### Identify a subset of species for modelling

Of the 200 species identified as candidates for modelling, 84 were only recorded in 1 or 2 experimental plots (most of the latter being in a single site). 

The threshold number of occurrences set to include a species for modelling is hard to define, but given the complexity of the models to be fitted, a minimum of 5 plot occurrences is a reasonable starting point.

We also remove Eucalpytus camaldulensis (present in all sites) from the data set.

```{r}

SpeciesSubset <- SPECIES.summary %>%
  filter(nplots >= 5) %>%
  
  left_join(SPECIES.info, by = c("workingcode", "workingname")) %>%
  
  # remove red gums
  filter(workingname != "Eucalyptus camaldulensis")

cat("Subset with", nrow(SpeciesSubset), "taxa", 
    "of which", sum(SpeciesSubset$weed), "are exotic \n")

```


### Species occurrence data matrix for modelling

```{r}

DAT.occurrence.subset <- DAT.occurrence.long %>%
  filter(workingcode %in% SpeciesSubset$workingcode)

# Format response data as a matrix for boral
M.y <- DAT.occurrence.subset %>%
  mutate(present = 1) %>%
  tidyr::spread(workingcode, present, fill=0) %>%
  
  # Order should be fine but just in case...
  arrange(site, plot9ha)


SiteLookup <- M.y %>%
  select(site, plot = plot9ha, siteplot) %>%
  left_join(
    SITES %>% select(site, plot, site.quality),
    by = c("site", "plot")
  ) %>%
  
  left_join(DAT.floodgroup, by = c("site", "plot", "siteplot"))


M.y <- as.matrix(M.y[ , -(1:3)])
rownames(M.y) <- SiteLookup$siteplot

```

## Model 3A - stem density and flood groups

### Model code

The code is based on the BORAL-generated JAGS code for model 3 combined with the JAGS code for the stem count model (see `model_subplot_stems_JAGS.Rmd`).

Note - this model imputes stem counts within the size classes used for field measurements, and then aggregates the resulting counts. It would probably be better (more precise estimates) to aggregate the input count data into the desired size classes and model these directly. We do this in model 3C (later in this doc).

```{r}

model3A.Code <- "model {
  # Model mean stem count by size class within each plot
  # Counts are treated as negative binomial - implemented as
  # Poisson with Gamma-distributed mean
  for (i in 1:length(nstems)) {
    nstems[i] ~ dpois(mu.stems[plot[i], sz[i]] * h[i])
    h[i] ~ dgamma(theta[sz[i]], theta[sz[i]])
  }

  # Priors for stem count model
  for (sz in 1:11) {
    # Estimate dispersion independently for each size class
    theta[sz] ~ dexp(1)

    # Overall mean stems (log scale) for each size class
    logmu.size[sz] ~ dnorm(0, 5)

    sd.size[sz] ~ dunif(0, 5)
    tau.size[sz] <- pow(sd.size[sz], -2)
    
    for (i in 1:66) {
      logmu.stems[i, sz] ~ dnorm(logmu.size[sz], tau.size[sz])
      mu.stems[i, sz] <- exp(logmu.stems[i, sz])
    }
  }
  
  # Aggregate modelled stem counts for field size classes into
  # the broader size classes to which species will be related
  for (i in 1:nplots) {
    for (k in 1:nsizeclasses) {
      # MinSize and MaxSize are the start and end indices of field
      # size classes for each aggregated size class
      X.stems[i, k] <- sum(mu.stems[i, (MinSize[k]):(MaxSize[k])])
    }
  }
  
  # Model species occurrence
  for(i in 1:nplots) {
    for(j in 1:nspecies) { 
      eta[i,j] <- inprod(lv.coefs[j,2:(num.lv+1)],lvs[i,]) + 
        row.coefs.ID1[i] + 
        flood.coefs[j, floodgroup[i]] +
        inprod(stem.coefs[j,], X.stems[i,])
    
      Z[i,j] ~ dnorm(lv.coefs[j,1] + eta[i,j], 1)
      y[i,j] ~ dbern(step(Z[i,j]))

      loglik[(i-1)*(nspecies)+j] <- y[i,j] * log(phi(lv.coefs[j,1] + eta[i,j])) + 
                                 (1 - y[i,j])*log(1 - phi(lv.coefs[j,1] + eta[i,j]))
    }
  }
  
  ## Latent variables ##
  for(i in 1:nplots) { for(k in 1:num.lv) { lvs[i,k] ~ dnorm(0,1) } } 
  
  ## Process level and priors ##
  for(j in 1:nspecies) { lv.coefs[j,1] ~ dnorm(0,0.1) } ## Separate species intercepts
  
  for(i in 1:nplots) { 
    row.coefs.ID1[i] ~ dnorm(0, pow(row.sigma.ID1,-2)) 
  } 
  row.sigma.ID1 ~ dunif(0,30)
  
  for(i in 1:(num.lv-1)) { 
    for(j in (i+2):(num.lv+1)) {
      # Constraints to 0 on upper diagonal
      lv.coefs[i,j] <- 0 
    } 
  }
  
  for(i in 1:num.lv) { 
     # Sign constraints on diagonal elements
    lv.coefs[i,i+1] ~ dnorm(0,0.1)I(0,) 
  }
  
  for(i in 2:num.lv) { 
    for(j in 2:i) { 
      # Free lower diagonals
      lv.coefs[i,j] ~ dnorm(0,0.1) 
    } 
  }
  
  for(i in (num.lv+1):nspecies) { 
    for(j in 2:(num.lv+1)) { 
      # All other elements
      lv.coefs[i,j] ~ dnorm(0,0.1)
    } 
  }
  
  # species coefficients on flood group and stem density
  # drawn from Laplace priors with variance equal to that of 
  # the boral default priors (10).

  laplace.scale <- sqrt(2 / 10)
  for(j in 1:nspecies) { 
    # coefficient on flood group
    for (kflood in 1:3) {
      flood.coefs[j, kflood] ~ ddexp(0, laplace.scale) 
    }

    for (ksize in 1:nsizeclasses) {
      stem.coefs[j,ksize] ~ ddexp(0, laplace.scale)
    }
  }
}"

```


### Data objects for model

```{r}

# Aggregated size classes for modelling

SizeClasses <- c("less10cm", "from10to20cm", "from20to30cm",
                 "from30to40cm", "from40to80cm", "from80cm")

FieldToModelSizeClass <- list(
  1, 2, 3, 4, 5:8, 9:11
)

# JAGS will not work with the lookup list FieldToModelSizeClass
# directly, so we create vector versions
MinSize <- sapply(FieldToModelSizeClass, min)
MaxSize <- sapply(FieldToModelSizeClass, max)

# Stem data
stems.dir <- here::here("..", "red_gum_thinning", "stem_densities")

dat.stems.observed <- load_from(file.path(stems.dir, "data", "stems_complete.RData")) %>%
  # Subset to control and pre-thinning plot data
  filter(survey %in% c("control", "pre.thinning")) %>%
  
  arrange(site, plot, subplot) %>%
  
  select(site, plot, !!(SIZES$sizeclass)) %>%
  
  tidyr::gather(sizeclass, nstems, -c(site, plot)) %>%
  
  filter(!is.na(nstems)) %>%
  
  mutate(plotindex = 3*(site-1) + plot,
         sz = match(sizeclass, SIZES$sizeclass)) %>%
  
  select(plot = plotindex, sz, nstems)



model3A.data <- list(
  y = M.y,
  floodgroup = as.integer(SiteLookup$floodgroup),
  nplots = nrow(M.y),
  nspecies = ncol(M.y),
  
  num.lv = 2,
  
  # stem counts
  plot = dat.stems.observed$plot,
  sz = dat.stems.observed$sz,
  nstems = dat.stems.observed$nstems,
  nsizeclasses = length(SizeClasses),
  MinSize = MinSize,
  MaxSize = MaxSize
)

```


### Compile and run the model

```{r}

# Function to generate initial values for Z: matrix of probit values.
# Takes the matrix of sites x species occurrences as an argument.
#
fn_Zinit <- function(y) {
  nc <- ncol(y)
  nr <- nrow(y)
  
  Tau <- rWishart(1, nc + 1, diag(nc))[, , 1]
  Sigma <- solve(Tau)

  Z <- abs(t(mvtnorm::rmvnorm(nr, rep(0, nc), Sigma)))
  Z <- ifelse(as.matrix(y), Z, -1 * Z)
  
  Z
}


Model3A.Path <- here::here("models", "fitted", "model3A_mcmc.RData")

if (REFIT_MODELS || !file.exists(Model3A.Path)) {
  model3A <- R2jags::jags(
    data = model3A.data, 
    inits = list(list(Z = fn_Zinit(M.y))), 
    parameters.to.save = c("flood.coefs",
                           "loglik",
                           "lvs", "lv.coefs", 
                           "mu.stems",
                           "row.coefs.ID1",
                           "row.sigma.ID1",
                           "stem.coefs"), 
    model.file = textConnection(model3A.Code),
    n.chains = 1, 
    n.iter = 210000, 
    n.burnin = 10000, 
    n.thin = 20)
  
  
  model3A.samples <- coda::mcmc(model3A$BUGSoutput$sims.matrix, start = 1, thin = 1)
  save(model3A.samples, file = Model3A.Path)
  
} else {
  model3A.samples <- load_from(Model3A.Path)
}
  
```


Separate posterior samples into those for parameters and those for species x plot log-likelihoods.

```{r}

ii <- str_detect(colnames(model3A.samples), "loglik")
model3A.loglik <- as.matrix( model3A.samples[, ii] )
model3A.samples <- model3A.samples[, !ii]

```


### Check model convergence for parameters

Geweke's diagnostic for model convergence.

```{r}

g <- coda::geweke.diag(model3A.samples)
ok <- (2 * pnorm(abs(g$z), lower.tail = FALSE) > 0.05)
p <- sum(ok, na.rm = TRUE) / length(na.omit(ok))

cat(round(p * 100, 2), "percent of parameters converged")

```

Manual inspection of sample traces for the parameters that did not satisfy the Geweke test suggested that they had converged.


Check for parameters with less than 4000 effectively independent samples. Note, parameter lv.coefs[1,3] will always have zero effective samples because its value is fixed at zero in the model.

```{r}

x <- coda::effectiveSize(model3A.samples)
ii <- x < 4000

if (sum(ii) > 1) {
  cat(sum(ii) - 1, "free parameters with less than 4000 samples\n")
  print(x[ii])
} else {
  cat("All free parameters have at least 4000 samples")
}

```

Convert posterior samples to a plain matrix.

```{r}

model3A.samples <- as.matrix(model3A.samples)

```


### Model results

#### Mean stem density estimates

Here we compare the mean stem density estimates made by the integrated model to observed sub-plot counts and estimates made by the separate JAGS stem density model. The interest here is in the degree of influence that species occurrence data had on stem density estimates in the integrated model.

In the following graphs for each 9ha plot, points show observed stem counts for 0.1ha sub-plots; the solid line and surrounding shaded region show the model's estimates of mean stem density; and the dashed line shows the corresponding estimates from the separate JAGS stem density model. The degree of separation between the solid and dashed lines reflects the strengh of influence of patterns of species occurrence over all plots.


```{r}

ii <- str_detect(colnames(model3A.samples), "mu.stems")

# Summary statistics for stem density means fitted in the itegrated model
dat.stems.fitted <- model3A.samples[, ii] %>%
  as.data.frame() %>%
  
  mutate(iter = row_number()) %>%
  tidyr::gather(param, value, -iter) %>%
  
  mutate(nums = str_extract(param, "\\d+\\,\\d+"),
         plot = as.integer(str_extract(nums, "^\\d+")),
         sizeclass = as.integer(str_extract(nums, "\\d+$"))) %>%
  
  group_by(plot, sizeclass) %>%
  do({
    mid <- median(.$value)
    q95 <- hpdi(.$value, 0.95)
    
    data.frame(lwr95 = q95[1, "lower"],
               mid = mid,
               upr95 = q95[1, "upper"])
  })


# Median estimages of stem means from the separately fitted JAGS model
path <- here::here("models", "fitted", "jags_subplotstems_median_params.RData")

dat.stems.jags <- load_from(path) %>%
  data.frame(param = names(.), mid = .) %>%
  filter(str_detect(param, "^mu")) %>%
  
  mutate(nums = str_extract(param, "\\d+\\,\\d+"),
         plot = as.integer(str_extract(nums, "^\\d+")),
         sizeclass = as.integer(str_extract(nums, "\\d+$"))) %>%
  
  select(plot, sizeclass, mid)


# Function to draw graphs for a subset of data
fn_plot <- function(the.plots) {
  dat.obs <- dat.stems.observed %>% filter(plot %in% the.plots)
  
  dat.fit <- dat.stems.fitted %>% 
    filter(plot %in% the.plots) %>% 
    mutate(set = "Integrated model")
  
  dat.jags <- dat.stems.jags %>% 
    filter(plot %in% the.plots) %>%
    mutate(set = "Stems model")

  
  xbreaks <- seq(2, 10, 2)
  
  ggplot() +
    geom_jitter(data = dat.obs, 
               aes(x = sz, y = nstems),
               height = 0, width = 0.1, shape = 1) +
    
    geom_ribbon(data = dat.fit, 
                aes(x=sizeclass, ymin=lwr95, ymax=upr95), 
                colour = "grey", alpha=0.25, show.legend = FALSE) +
    
    geom_line(data = dat.fit, 
              aes(x = sizeclass, y=mid), 
              colour = "black", linetype = "solid") +
    
    geom_line(data = dat.jags, 
              aes(x = sizeclass, y=mid), 
              colour = "black", linetype = "dashed") +
    
    scale_x_continuous(breaks = xbreaks, labels = 10*xbreaks) +
    
    labs(x = "Tree size class", y = "Number of stems per 0.1ha")
}


facet.labels <- paste(
  rep(1:22, each=3),
  rep(1:3, 22),
  sep = ":"
)

names(facet.labels) <- 1:66

```

```{r fig.height=8}

for (i in seq(1, 66, 6)) {
  the.plots <- i:(i+5)
  
  print( fn_plot(the.plots) +
           facet_wrap(~ plot, scales = "free_y", 
               labeller = as_labeller(facet.labels)) )
}

```


#### Species coefficients on stem density

The graph below shows median values for species coefficients on stem density for each of the six (grouped) tree size classes based on data over all plots. Positive values indicate a higher probability of occurrence and negative values a lower probability. 

Warning!! This is breaking McElreath's rule - "You should not try to interpret a non-trivial model by examining coefficients. Instead look at predictions."


```{r}

ii <- str_detect(colnames(model3A.samples), "^stem.coefs")

x <- apply(model3A.samples[, ii], MARGIN=2, median)

model3A.stemeffects <- data.frame(
  param = names(x),
  median.value = x,
  stringsAsFactors=FALSE) %>%
  
  mutate(nums = str_extract(param, "\\d+\\,\\d+"),
         spnum = as.integer(str_extract(nums, "^\\d+")),
         sizeclass = as.integer(str_extract(nums, "\\d+$"))) %>%
  
  # Scale coefficient values within each size class to account
  # for the unstandardized stem counts used in the model
  group_by(sizeclass) %>%
  mutate(median.value = scale(median.value)) %>%
  ungroup() %>%
  
  # Add species info
  left_join(SpeciesSubset %>% mutate(spnum = row_number()),
            by = "spnum") %>%
  
  mutate(status = ifelse(is.na(weed), "Indet", ifelse(weed, "Exotic", "Native")),
         group = ifelse(status == "Exotic", "exotic", 
                        ifelse(habitat == "terrestrial", "dry", "wet")) ) %>%

  select(spnum, workingname, status, group, sizeclass, median.value)
  

# Cluster species based on their vectors of sizeclass variable inclusion rates.
# Do this separately for native/dry, native/wet and exotic species
x <- model3A.stemeffects %>%
  tidyr::spread(sizeclass, median.value, sep="_") %>%

  group_by(group) %>%
  do (
    {
      n <- nrow(.)
      d <- dist(.[, paste0("sizeclass_", 1:6)])  # euclidean distance
      h <- hclust(d, method = "complete")
      data.frame(spnum = .$spnum[h$order], rank = 1:n)
    }
  )


dat.gg <- left_join(model3A.stemeffects, x, 
                    by = c("spnum", "group"))

# Record order of species names to use as factor levels for ggplot
levels <- dat.gg %>%
  arrange(group, rank) %>%
  distinct(workingname)

dat.gg <- dat.gg %>%
  mutate(workingname = factor(workingname, levels = levels$workingname),
         group = factor(group, 
                        levels = c("exotic", "dry", "wet"),
                        labels = c("Exotic", "Native dry", "Native damp/wet")))

```


```{r fig.height=12, fig.width=8}

xlabels <- SizeClasses %>%
  str_replace("less", "<") %>%
  str_replace("from", "") %>%
  str_replace("to", "-")

i <- length(xlabels)
xlabels[i] <- paste0(">", xlabels[i])


gg <- ggplot(data = dat.gg) +
  geom_raster(aes(x = sizeclass, y = workingname, fill = median.value)) +
  
  scale_fill_gradient2(name = "Effect",
                       low = "#7b3294", mid = "#fafafa", high = "#008837") +
  
  scale_x_continuous(breaks = 1:6, labels = xlabels) +
  
  labs(x = "Size class", y = "Species",
       title = "Median species coefficients on stem size classes") +
  
  facet_grid(group ~ ., scales = "free_y", space = "free_y")


gg_pdf(plot = gg, 
       file = here("models/outputs/model3A_stem_effects.pdf"), 
       size = pagesize("A3"))

print(gg)

```


#### Predict on training data

We derive predictions for the occurrence of each species in each plot based on the training data, i.e. posterior predictive checking of the model. For each species x plot case, predicted probability of occurrence is based on the plot-level random effect, the two plot latent variable values, the six mean values for fitted mean stem density within size class, and the plot's flood group.

Predicted probability of occurrence for species i in plot j is given by:

```
 phi(p) = lv.coefs[i,1] + 
          lv.coefs[i,2:3] %*% lvs[j,1:2] +
          flood.coefs[i, flood.group[j]] +
          stem.coefs[i, 1:6] %*% X.stems[j, 1:6] +
          row.coefs[j]
          
 where X.stems is grouped sums of individual size class means mu.stems
```

```{r}

Model3A.linpred.Path <- here::here("models", "fitted", "model3A_linpred.RData")

nplots <- model3A.data$nplots
nspecies <- model3A.data$nspecies
nfloodgrp <- n_distinct(model3A.data$floodgroup)
nsizeclasses <- model3A.data$nsizeclasses

if (REFIT_MODELS || !file.exists(Model3A.linpred.Path)) {

  # Check that we have the correct lookup list for field to
  # model size classes
  stopifnot(length(FieldToModelSizeClass) == nsizeclasses)
  
  niter <- nrow(model3A.samples)
  
  get_indices <- function(ptn, n.expected = NULL) {
    ii <- str_detect(colnames(model3A.samples), ptn)
    if (!is.null(n.expected)) {
      stopifnot(sum(ii) == n.expected)
    }
    ii
  }
  
  ii.lvcoefs <- get_indices("lv.coefs", nspecies * 3)
  ii.stemcoefs <- get_indices("stem.coefs", nspecies * nsizeclasses)
  ii.floodcoefs <- get_indices("flood.coefs", nspecies * nfloodgrp)
  ii.rowcoefs <- get_indices("row.coefs", nplots)

  ii.lvs <- get_indices("lvs", nplots * 2)
  ii.mu.stems <- get_indices("mu.stems", nplots * 11) # 11 field size classes
  
  m.floodgroup <- matrix(0, nrow = nplots, ncol = nfloodgrp)
  ii <- cbind(1:nplots, model3A.data$floodgroup)
  m.floodgroup[ii] <- 1
  
  model3A.linpred <- array(0, dim = c(nplots, nspecies, niter))
  
  for (ipost in 1:niter) {
    # contribution of species intercept and latent variables
    lv.coefs <- matrix(model3A.samples[ipost, ii.lvcoefs], nrow = nspecies)
    lvs <- cbind(1, matrix(model3A.samples[ipost, ii.lvs], nrow = nplots))
    eta <- tcrossprod(lvs, lv.coefs)
    
    # contribution of stem density
    stem.coefs <- matrix(model3A.samples[ipost, ii.stemcoefs], nrow = nspecies)
    mu.stems <- matrix(model3A.samples[ipost, ii.mu.stems], nrow = nplots)
    
    # aggregate modelled field counts to the broader six size classes
    X.stems <- lapply(FieldToModelSizeClass, function(cols) {
      x <- rep(0, nplots)
      for (k in cols) {
        x <- x + mu.stems[,k]
      }
      x
    })
    X.stems <- do.call(cbind, X.stems)
    
    eta <- eta + tcrossprod(X.stems, stem.coefs)
    
    # contribution of flood group
    flood.coefs <- matrix(model3A.samples[ipost, ii.floodcoefs], nrow = nspecies)
    eta <- eta + tcrossprod(m.floodgroup, flood.coefs)
    
    # row effects (vector)
    row.coefs <- model3A.samples[ipost, ii.rowcoefs]
    eta <- eta + row.coefs
    
    model3A.linpred[,,ipost] <- eta
  }
  
  save(model3A.linpred, file = Model3A.linpred.Path)
  
} else {
  model3A.linpred <- load_from(Model3A.linpred.Path)
}

```


#### Compare predicted and observed species richness

Sum occurrence probabilities within each plot to arrive at posterior estimates of species richness, and compare to observed values.

```{r}

predicted.richness <- apply(model3A.linpred, MARGIN = 1, 
                            FUN = function(lp) {
                              # lp will have species as rows, samples as cols
                              rich <- colSums(pnorm(lp))
                              q50 <- unname( hpdi(rich, 0.5)[1,] )
                              q95 <- unname( hpdi(rich, 0.95)[1,] )
                              c(q95[1], q50[1], median(rich), q50[2], q95[2])
                            })

predicted.richness <- t(predicted.richness) 
colnames(predicted.richness) <- c("lwr95", "lwr50", "mid", "upr50", "upr95")

dat.gg <- as.data.frame(predicted.richness) %>%
  mutate(plot = row_number(),
         site = 1 + (plot - 1) %/% 3,
         observed = rowSums(model3A.data$y),
         label = ifelse(plot %% 3 == 2, site, ""))

dat.bkg <- dat.gg %>%
  group_by(site) %>%
  summarize(xmin = min(plot) - 0.5, xmax = max(plot) + 0.5) %>%
  ungroup() %>%
  
  mutate(ymin = min(dat.gg$lwr95) - 1, 
         ymax = max(dat.gg$upr95) + 1,
         filled = site %% 2 == 0)

gg <- ggplot(data = dat.gg) +
  geom_rect(data = dat.bkg, 
            aes(xmin = xmin, xmax = xmax, 
                ymin = ymin, ymax = ymax,
                fill = filled),
            show.legend = FALSE) +
  
  scale_fill_manual(values = c("#ffffff00", "#dfdfdfff")) +
  
  geom_linerange(aes(x = plot, ymin = lwr95, ymax = upr95),
                 size = 0.75, colour = "grey50") +
  
  geom_linerange(aes(x = plot, ymin = lwr50, ymax = upr50),
                 size = 2.5, colour = "grey50") +
  
  geom_point(aes(x = plot, y = observed), size = 4) +
  
  scale_x_continuous(breaks = 1:66, labels = dat.gg$label) +
  
  scale_y_continuous(limits = c(9,51)) +
  
  labs(x = "Site", y = "Species richness",
       title = "Comparison of observed and predicted species richness within 9ha plots",
       subtitle = paste("Points are observed values.",
                        "Thick and thin lines are 50% and 95% HPD intervals.")) +
  
  coord_flip() +
  
  theme(axis.ticks.y = element_blank())


gg_pdf(gg, "model3A_postpred_check_richness.pdf", pagesize('A4', 'portrait'))

print(gg)

```


Next we examine the predictions for individual species occurrence in plots and compare these to the observations.

```{r}

# This will give summary matrices for each species stacked
# one on the other
predicted.occurrence <- lapply(1:nspecies, function(sp) {
  lp <- model3A.linpred[,sp,]
  
  # transpose matrix lp to have samples as rows, plots as columns
  lp <- t(lp)
  prob <- pnorm(lp)
  
  q50 <- hpdi(prob, 0.5)
  q95 <- hpdi(prob, 0.95)
  
  q <- cbind(sp,
             plot = 1:ncol(prob),
             lwr95 = q95[,1],
             lwr50 = q50[,1],
             mid = apply(prob, MARGIN = 2, median),
             upr50 = q50[,2],
             upr95 = q95[,2])

  q
})

predicted.occurrence <- do.call(rbind, predicted.occurrence)

x <- as.data.frame(model3A.data$y)
colnames(x) <- 1:ncol(x)

x <- x %>%
  mutate(plot = row_number()) %>%
  tidyr::gather(sp, observed, -plot, convert = TRUE)

dat.gg.all <- predicted.occurrence %>%
  as.data.frame() %>%
  left_join(x, by = c("plot", "sp")) %>%
  mutate(observed = factor(observed, levels = 0:1, labels = c("absent", "present")))


labels <- SpeciesSubset$workingname
names(labels) <- 1:length(labels)


plot_fn <- function(the.spp) {
  dat.gg <- dat.gg.all %>%
    dplyr::filter(sp %in% the.spp)

  ggplot(data = dat.gg, aes(x = plot)) +
    geom_point(aes(y = mid, shape = observed),
               size = 3, alpha = 0.6) +
    
    scale_shape_manual(breaks = c("absent", "present"), values = c(1, 16)) +
    
    labs(x = "Plot order", y = "Probability of occurrence") +
    
    facet_wrap(~ sp, labeller = as_labeller(labels)) +
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank())
}

```


```{r}

for (i in seq(1, 95, 6)) {
  the.spp <- i:min(i+5, 95)
  
  gg <- plot_fn(the.spp)
  
  filename <- paste0("species_probs_", min(the.spp), "_", max(the.spp), ".pdf")
  gg_pdf(gg, filename)
  
  print(gg)
}

```


#### Predictions for new site data

The following function derives predictions given new site data. The code is adapted from the `boral::predict` function for marginal predictions using Monte Carlo integration over latent variables.

Note that the function *assumes* parameter names used with model 3A, and the matrix algebra used within the function *assumes* that groups of parameters (e.g. 'lv.coefs') are arranged in the same order as they would be in output from a `boral` model. Terrible things will happen silently if this is not the case!

```{r}

predict_new_sites <- function (post.samples, 
                               Xstems, 
                               floodgroups = 1:3, 
                               num.lv = 2, sd.lv = 1, lv.mc = 1000) {

  stopifnot(is.matrix(post.samples))

  post.names <- colnames(post.samples)
  
  # Function to get indices of specified parameters from posterior matrix
  get_indices <- function(param.label, num.expected = NULL) {
    ii <- str_detect(post.names, param.label)
    nii <- sum(ii)
    
    if (is.null(num.expected)) {
      if (nii == 0) stop(param.label, " is not in post.samples")
    } else if (nii != num.expected) {
      msg <- paste("Expected", num.expected, "variables for", param.label, "but found", nii)
      stop(msg)
    }
    
    ii
  }
  
  
  # check number of species, tree size classes and flood 
  # groups by looking at posterior samples
  ii <- get_indices("flood.coefs")
  inds <- str_extract(post.names[ii], "\\d+,\\d+")
  nspp <- length(unique(str_extract(inds, "^\\d+")))
  
  # Number of flood groups in posterior samples
  npostflood <- length(unique(str_extract(inds, "\\d+$")))

  # Number of flood groups to do predictions for
  nflood <- length(floodgroups)
  
  ii <- get_indices("stem.coefs")
  inds <- str_extract(post.names[ii], "\\d+,\\d+")
  nsizes <- length(unique(str_extract(inds, "\\d+$")))
  
  
  stopifnot(is.matrix(Xstems), 
            ncol(Xstems) == nsizes)

  nsites <- nrow(Xstems)
  
  stopifnot(is.vector(floodgroups),
            is.numeric(floodgroups),
            nflood <= npostflood,
            all(floodgroups %in% 1:npostflood))
  
  
  Xflood <- array(0, dim = c(nflood, nsites, npostflood))
  for (f in 1:nflood) {
    for (i in 1:nsites) Xflood[f, i, floodgroups[f]] <- 1
  }

  
  # Array to store linear predictor values for sites X spp X flood groups
  all_linpred <- array(NA, dim = c(nsites, nspp, nflood, nrow(post.samples)))


  # Latent variable values from multi-variate normal where all 
  # off-diagonal covariances are 0
  mc_lv <- rnorm(nsites * lv.mc * num.lv, mean = 0, sd = sd.lv)
  mc_lv <- array(mc_lv, dim = c(lv.mc, nsites, num.lv))
    
  
  # Array to hold linear predictor values for one posterior sample
  # and one flood group over all tuples of MC latent variables
  all_linpredmc <- array(NA, dim = c(nsites, nspp, lv.mc))
  
  # Loop through posterior samples
  pb <- txtProgressBar(max = nrow(post.samples), style = 3)
  for (ipost in 1:nrow(post.samples)) {
    setTxtProgressBar(pb, ipost)
    
    ii <- get_indices("lv.coefs", nspp * (num.lv + 1))
    lvcoefs <- matrix(post.samples[ipost, ii], nrow = nspp)
    
    ii <- get_indices("stem.coefs", nspp * ncol(Xstems))
    stemcoefs <- matrix(post.samples[ipost, ii], nrow = nspp)
    
    ii <- get_indices("flood.coefs", nspp * npostflood)
    floodcoefs <- matrix(post.samples[ipost, ii], nrow = nspp)
    
    Xcoefs <- cbind(stemcoefs, floodcoefs)
    
    ii <- get_indices("row.sigma", 1)
    rowcoefs <- matrix(
      rnorm(nsites * lv.mc, mean = 0, sd = post.samples[ipost, ii]), 
      ncol = lv.mc )
    
    for (f in 1:nflood) {
      X <- cbind(Xstems, Xflood[f,,])

      for (b in 1:lv.mc) {
        eta <- tcrossprod(mc_lv[b, , ], lvcoefs[, 2:(num.lv + 1)])
        
        eta <- eta + 
          tcrossprod(cbind(1, X), cbind(lvcoefs[, 1], Xcoefs))
        
        # note: this relies on recyling the vector of row coefs across
        # columns of the matrix eta
        eta <- eta + rowcoefs[, b]
        
        all_linpredmc[, , b] <- eta
        rm(eta)
      }
      
      all_linpred[, , f, ipost] <- apply(all_linpredmc, c(1,2), mean)
    }
    
    all_linpredmc[,,] <- NA
  }
  close(pb)
  
  # Return array of linear predictor values [site, sp, floodgroup, sample]
  all_linpred
}

```


##### Create data for a range of stand structures

We create a set of artificial sites covering a range of stand configurations (size X density combinations). These are based on quantiles of **mean** stem counts within grouped diameter size classes

We use the posterior samples of mean stem counts from model 3A. This takes into account the different number of sub-plots for the smallest size class. We treat each posterior sample as a sub-plot observation to get quantiles that reflect the range of fitted means.

```{r}

# Retrieve posterior samples for mean stem counts within plot X size class.
# This assumes mu.stems params are ordered by plot (first index) within size 
# class (second index)
# i.e. mu.stems[plot1, sz1], mu.stems[plot2, sz1] ... mu.stems[plot66, sz11]
ii <- str_detect(colnames(model3A.samples), "mu.stems")

nr <- nrow(model3A.samples)
dat.mu <- array(NA, dim = c(66, 11, nr))
for (r in 1:nr) dat.mu[,,r] <- model3A.samples[r,ii]

# Group size classes as per model: 1,2,3,4,5-8,9-11
for (r in 1:nr) {
  dat.mu[,5,r] <- rowSums(dat.mu[,5:8,r])
  dat.mu[,6,r] <- rowSums(dat.mu[,9:11,r])
}
dat.mu <- dat.mu[,1:6,]


# Determine quantiles for each size class
probs <- seq(0.1, 0.9, 0.1)
qdat <- sapply(1:6, function(sz) quantile(dat.mu[,sz,], probs))
  
```


New sites with varying density of selected (grouped) size classes:

```{r}

# Small trees (first two size classes, <=20cm); other size classes set to median values
Xstems.small <- qdat
for (k in 3:6) Xstems.small[,k] <- qdat[5,k]


# New sites with varying density of intermediate size classes (<30cm, <40cm)
Xstems.intermediate <- qdat
for (k in c(1,2,5,6)) Xstems.intermediate[,k] <- qdat[5,k] 

# New sites with varying density of the largest trees (<80cm, >80cm)
Xstems.large <- qdat
for (k in 1:4) Xstems.large[,k] <- qdat[5,k]

# New sites with varying density of all but the largest size class.
Xstems.all <- qdat
Xstems.all[,6] <- qdat[5,6]

```


Combine data and allow for duplicate records (all size classes at median value).

```{r}

fn <- function(x) as.data.frame(x)

Xstems.new <- bind_rows(
  fn(Xstems.small), 
  fn(Xstems.intermediate), 
  fn(Xstems.large), 
  fn(Xstems.all) )

sznames <- c("<10cm", "<20cm", "<30cm", "<40cm", "<80cm", ">80cm")
colnames(Xstems.new)[1:6] <- sznames

Xstems.new <- Xstems.new %>%
  mutate(label = rep(c("small", "intermediate", "large", "all"), each = nrow(qdat)),
         label = paste0(label, probs * 100),
         index = row_number())


# There will be duplicate records for trees at median density. We only pass
# one of these to the prediction function (because it is so slow)
median.recs <- which( apply(Xstems.new[,1:6], 1, function(xs) all(xs == qdat[5,])) )
stopifnot(length(median.recs) == 4)

Xstems.new.predict <- Xstems.new[-median.recs[-1], ]


# Make a lookup table to use when summarizing and graphing predictions.
# It relates data row numbers to prediction row numbers.
fn <- function(index, median.recs) {
  delta <- findInterval(index, median.recs[-1])
  delta[median.recs] <- NA
  ifelse(index %in% median.recs, median.recs[1], index - delta)
}

Xstems.lookup <- Xstems.new %>%
  select(label, data.index = index) %>%
  mutate(prediction.index = fn(data.index, median.recs))

```


##### Compare artificial sites to actual sites

We use MDS to display the relationship between the artificial data and the actual data (represented by median posterior stem density values from model 3A).

```{r}

# Median posterior stem densities for actual sites
dat.actual <- apply(dat.mu, MARGIN = 1:2, median) %>%
  as.data.frame()

colnames(dat.actual) <- sznames

dat.all <- bind_rows(
  dat.actual %>% mutate(label = "actual"),
  Xstems.new.predict %>% select(-index)
)

d <- dat.all %>% 
  select(-label) %>%
  scale(.) %>%
  vegan::vegdist("euclidean")

mds <- vegan::metaMDS(d)

dat.gg <- mds$points %>%
  as.data.frame() %>%
  mutate(label = dat.all$label,
         label = str_extract(label, "^[a-z]+"),
         grp = ifelse(label == "actual", "observed", "artificial"))


gg <- ggplot(data = dat.gg) +
  geom_point(aes(x = MDS1, y = MDS2, colour = label, shape = grp),
             size = 3) +
  
  scale_colour_discrete(name = "Data set") +
  scale_shape_manual(name = "Data type", values = c(16, 1)) +
  
  labs(title = "Ordination of stem density data for actual and artificial sites")

```


##### Do predictions

```{r}

path <- here::here("models", "predictions", "model3A_new_site_predictions.RData")

if (REFIT_MODELS || !file.exists(path)) {
  res <- predict_new_sites(post.samples = model3A.samples,
                           Xstems = as.matrix(Xstems.new.predict[, 1:6]))
  
  save(res, file = path)

} else {
  res <- load_from(path)
}

```


##### Species richness predictions for 9ha plots

Display predictions for the different stand configurations over each of the three flood groups.

```{r}

dat <- lapply(1:3, function(floodgrp) {
  x <- res[,,floodgrp,]
  rich <- apply(x, MARGIN = c(1,3), FUN = function(lp) sum(pnorm(lp)))
  hpd50 <- hpdi(t(rich), 0.5)
  hpd95 <- hpdi(t(rich), 0.95)
  
  data.frame(prediction.index = 1:nrow(rich),
             floodgrp = floodgrp, 
             lwr95 = hpd95[,1],
             lwr50 = hpd50[,1],
             mid = apply(rich, MARGIN = 1, FUN = median),
             upr50 = hpd50[,2],
             upr95 = hpd95[,2]
  )
})

dat <- bind_rows(dat)

dat.gg <- Xstems.lookup %>%
  left_join(dat, by = "prediction.index") %>%
  
  mutate(grp = str_extract(label, "^[a-z]+"),
         quant = as.integer(str_extract(label, "\\d+"))) %>%
  
  mutate(label = factor(label, levels = unique(label)),
         floodgrp = factor(floodgrp))

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0.8

gg <- ggplot(data = dat.gg, aes(x = label, colour = grp)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95, group = floodgrp),
                 position = position_dodge(width = dodgew),
                 size = 0.5) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50, group = floodgrp), 
                 position = position_dodge(width = dodgew),
                 size = 1) +
  
  geom_point(aes(y = mid, shape = floodgrp),
             position = position_dodge(width = dodgew),
             size = 2.5) +
  
  scale_color_discrete(name = "Varying size classes") +
  scale_shape_discrete(name = "Flood group") +
  
  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  # facet_wrap(~ floodgrp, labeller = label_both) +
  
  theme(panel.grid.major.x = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_newsites_richness.pdf", size = pagesize())

print(gg)

```


##### Native vs exotic species richness predictions for 9ha plots

Display predictions for the different stand configurations, marginalized over all three flood groups.

```{r}

native.indices <- which(!SpeciesSubset$weed)
exotic.indices <- which(SpeciesSubset$weed)

# Function to calculate summary stats for richness over a 
# subset of species, marginalized over all flood groups
fn <- function(spp.indices) {
  rich <- lapply(1:3, function(floodgrp) {
    x <- res[, spp.indices, floodgrp,]
    apply(x, MARGIN = c(1,3), FUN = function(lp) sum(pnorm(lp)))
  })
  
  # summarize over all flood groups
  rich <- do.call(cbind, rich)
  hpd50 <- hpdi(t(rich), 0.5)
  hpd95 <- hpdi(t(rich), 0.95)
  
  data.frame(
    prediction.index = 1:nrow(rich),
    lwr95 = hpd95[,1],
    lwr50 = hpd50[,1],
    mid = apply(rich, MARGIN = 1, FUN = median),
    upr50 = hpd50[,2],
    upr95 = hpd95[,2]
  )
}


dat <- bind_rows(
  fn(native.indices) %>% mutate(status = "Native"),
  fn(exotic.indices) %>% mutate(status = "Exotic")
)


dat.gg <- Xstems.lookup %>%
  left_join(dat, by = "prediction.index") %>%
  
  mutate(grp = str_extract(label, "^[a-z]+"),
         quant = as.integer(str_extract(label, "\\d+")),
         label = factor(label, levels = unique(label)))

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0

gg <- ggplot(data = dat.gg, aes(x = label, colour = grp, group = status)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95),
                 position = position_dodge(width = dodgew),
                 size = 0.75) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50), 
                 position = position_dodge(width = dodgew),
                 size = 2) +
  
  geom_point(aes(y = mid, shape = status),
                 position = position_dodge(width = dodgew),
             size = 4) +
  
  scale_color_discrete(name = "Varying size classes") +

  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  # facet_wrap(~ status) +
  
  theme(panel.grid.major.y = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_newsites_richness_nat_ex.pdf", size = pagesize())

print(gg)

```


Alternative version of the above graph with the flood groups shown separately.

```{r}

native.indices <- which(!SpeciesSubset$weed)
exotic.indices <- which(SpeciesSubset$weed)

# Function to calculate summary stats for richness over a 
# subset of species, marginalized over all flood groups
fn <- function(spp.indices) {
  dats <- lapply(1:3, function(floodgrp) {
    x <- res[, spp.indices, floodgrp,]
    rich <- apply(x, MARGIN = c(1,3), FUN = function(lp) sum(pnorm(lp)))
  
    hpd50 <- hpdi(t(rich), 0.5)
    hpd95 <- hpdi(t(rich), 0.95)
  
    data.frame(
      prediction.index = 1:nrow(rich),
      floodgrp = floodgrp,
      lwr95 = hpd95[,1],
      lwr50 = hpd50[,1],
      mid = apply(rich, MARGIN = 1, FUN = median),
      upr50 = hpd50[,2],
      upr95 = hpd95[,2]
    )
  })
  
  bind_rows(dats)
}


dat <- bind_rows(
  fn(native.indices) %>% mutate(status = "Native"),
  fn(exotic.indices) %>% mutate(status = "Exotic")
)


dat.gg <- Xstems.lookup %>%
  left_join(dat, by = "prediction.index") %>%
  
  mutate(grp = str_extract(label, "^[a-z]+"),
         quant = as.integer(str_extract(label, "\\d+")),
         label = factor(label, levels = unique(label)),
         floodgrp = factor(floodgrp))

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0.8

gg <- ggplot(data = dat.gg, aes(x = label, colour = grp, group = floodgrp)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95),
                 position = position_dodge(width = dodgew),
                 size = 0.5) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50), 
                 position = position_dodge(width = dodgew),
                 size = 1.0) +
  
  geom_point(aes(y = mid, shape = floodgrp),
                 position = position_dodge(width = dodgew),
             size = 2.0) +
  
  scale_color_discrete(name = "Varying size classes") +

  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  facet_wrap(~ status, scales = "free_x") +
  
  theme(panel.grid.major.y = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_newsites_richness_nat_ex_flood.pdf", size = pagesize())

print(gg)

```



#### Alternative predictions based on edge cases

Here we simplify the artificial sites, aggregating tree sizes into three groups as before (small <20cm; medium <40cm; large >40cm) but setting each to either the 10% or 90% quantile of the modelled mean stem density based on model 3A. This results in eight contrasting stand structures:

Small |Medium|Large |Description
------|------|------|------------
10    |10    |10    |Sparse stand
10    |10    |90    |Open stand with many large trees
10    |90    |10    |Moderate density with many intermediate trees
10    |90    |90    |Moderate density with many intermediate and large trees
90    |10    |10    |High density of small trees with few larger trees
90    |10    |90    |High density of small and large trees with few intermediate trees
90    |90    |10    |High density of small and intermediate trees with few large trees
90    |90    |90    |Uniformly high density stand 


##### Create data for a range of stand structures

We create a set of artificial sites covering a range of stand configurations (size X density combinations). These are based on quantiles of **mean** stem counts within grouped diameter size classes

We use the posterior samples of mean stem counts from model 3A. This takes into account the different number of sub-plots for the smallest size class. We treat each posterior sample as a sub-plot observation to get quantiles that reflect the range of fitted means.

```{r}

# Retrieve posterior samples for mean stem counts within plot X size class.
# This assumes mu.stems params are ordered by plot (first index) within size 
# class (second index)
# i.e. mu.stems[plot1, sz1], mu.stems[plot2, sz1] ... mu.stems[plot66, sz11]
ii <- str_detect(colnames(model3A.samples), "mu.stems")

nr <- nrow(model3A.samples)
dat.mu <- array(NA, dim = c(66, 11, nr))
for (r in 1:nr) dat.mu[,,r] <- model3A.samples[r,ii]

# Group size classes as per model: 1,2,3,4,5-8,9-11
for (r in 1:nr) {
  dat.mu[,5,r] <- rowSums(dat.mu[,5:8,r])
  dat.mu[,6,r] <- rowSums(dat.mu[,9:11,r])
}
dat.mu <- dat.mu[,1:6,]


# Determine quantiles for each size class
probs <- c(0.1, 0.9)
qdat <- sapply(1:6, function(sz) quantile(dat.mu[,sz,], probs))
  
```


Create new sites for the eight combinations of small, medium and large tree density (each at the 10% or 90% quantile)

```{r}

Lookup.8stands <- expand.grid(large = c(10, 90), 
                              medium = c(10,90), 
                              small = c(10,90)) %>%
  
  select(small, medium, large) %>%
  mutate_all(paste0, "%")
  

Xstems.8stands <- cbind(
  # small trees
  qdat[Lookup.8stands[, "small"],  1:2],
  qdat[Lookup.8stands[, "medium"], 3:4],
  qdat[Lookup.8stands[, "large"],  5:6]
)

rownames(Xstems.8stands) <- NULL

sznames <- c("<10cm", "<20cm", "<30cm", "<40cm", "<80cm", ">80cm")
colnames(Xstems.8stands) <- sznames

```


##### Compare artificial sites to actual sites

We use MDS to display the relationship between the artificial data and the actual data (represented by median posterior stem density values from model 3A).

```{r}

# Median posterior stem densities for actual sites
dat.actual <- apply(dat.mu, MARGIN = 1:2, median) %>%
  as.data.frame()

colnames(dat.actual) <- sznames

dat.all <- bind_rows(
  dat.actual %>% mutate(label = "actual"),
  as.data.frame(Xstems.8stands) %>% mutate(label = "artificial")
)

d <- dat.all %>% 
  select(-label) %>%
  scale(.) %>%
  vegan::vegdist("euclidean")

mds <- vegan::metaMDS(d)

dat.gg <- mds$points %>%
  as.data.frame() %>%
  mutate(label = dat.all$label)


dat.labels <- tail(dat.gg, nrow(Xstems.8stands)) %>%
  bind_cols(Lookup.8stands) %>%
  mutate(stand.desc = paste(small, medium, large, sep = "-"))


gg <- ggplot(data = dat.gg, aes(x = MDS1, y = MDS2)) +
  geom_point(aes(colour = label),
             size = 3) +
  
  scale_colour_discrete(name = "Data type") +
  
  geom_text_repel(data = dat.labels, aes(label = stand.desc)) +
  
  labs(title = "Ordination of stem density data for actual and artificial sites",
       subtitle = "Artificial sites labelled with quantiles for small-medium-large tree density") +
  
  coord_equal()


gg_pdf(gg, filename = "model3A_8stands_mds.pdf", size = pagesize())

print(gg)

```


##### Do predictions

```{r}

path <- here::here("models", "predictions", "model3A_new_8site_predictions.RData")

if (REFIT_MODELS || !file.exists(path)) {
  res <- predict_new_sites(post.samples = model3A.samples,
                           Xstems = Xstems.8stands)
  
  save(res, file = path)

} else {
  res <- load_from(path)
}

```



##### Native vs exotic species richness predictions for 9ha plots

Display predictions for the different stand configurations, marginalized over all three flood groups.

```{r}

native.indices <- which(!SpeciesSubset$weed)
exotic.indices <- which(SpeciesSubset$weed)

# Function to calculate summary stats for richness over a 
# subset of species, marginalized over all flood groups
fn <- function(spp.indices) {
  rich <- lapply(1:3, function(floodgrp) {
    x <- res[, spp.indices, floodgrp,]
    apply(x, MARGIN = c(1,3), FUN = function(lp) sum(pnorm(lp)))
  })
  
  # summarize over all flood groups
  rich <- do.call(cbind, rich)
  hpd50 <- hpdi(t(rich), 0.5)
  hpd95 <- hpdi(t(rich), 0.95)
  
  data.frame(
    prediction.index = 1:nrow(rich),
    lwr95 = hpd95[,1],
    lwr50 = hpd50[,1],
    mid = apply(rich, MARGIN = 1, FUN = median),
    upr50 = hpd50[,2],
    upr95 = hpd95[,2]
  )
}


dat <- bind_rows(
  fn(native.indices) %>% mutate(status = "Native"),
  fn(exotic.indices) %>% mutate(status = "Exotic")
)


dat.gg <- Lookup.8stands %>%
  mutate(prediction.index = row_number()) %>%
  
  left_join(dat, by = "prediction.index") %>%
  
  mutate(label = sprintf("sm%s-med%s-lg%s", small, medium, large))

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0.2

gg <- ggplot(data = dat.gg, aes(x = label, group = status)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95),
                 position = position_dodge(width = dodgew),
                 size = 0.75) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50), 
                 position = position_dodge(width = dodgew),
                 size = 2) +
  
  geom_point(aes(y = mid, shape = status),
                 position = position_dodge(width = dodgew),
             size = 4) +
  
  scale_color_discrete(name = "Varying size classes") +

  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  # facet_wrap(~ status) +
  
  theme(panel.grid.major.y = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_8stands_richness_nat_ex.pdf", size = pagesize())

print(gg)

```


Alternative version of the above graph with the flood groups shown separately.

```{r}

native.indices <- which(!SpeciesSubset$weed)
exotic.indices <- which(SpeciesSubset$weed)

# Function to calculate summary stats for richness over a 
# subset of species, marginalized over all flood groups
fn <- function(spp.indices) {
  dats <- lapply(1:3, function(floodgrp) {
    x <- res[, spp.indices, floodgrp,]
    rich <- apply(x, MARGIN = c(1,3), FUN = function(lp) sum(pnorm(lp)))
  
    hpd50 <- hpdi(t(rich), 0.5)
    hpd95 <- hpdi(t(rich), 0.95)
  
    data.frame(
      prediction.index = 1:nrow(rich),
      floodgrp = floodgrp,
      lwr95 = hpd95[,1],
      lwr50 = hpd50[,1],
      mid = apply(rich, MARGIN = 1, FUN = median),
      upr50 = hpd50[,2],
      upr95 = hpd95[,2]
    )
  })
  
  bind_rows(dats)
}


dat <- bind_rows(
  fn(native.indices) %>% mutate(status = "Native"),
  fn(exotic.indices) %>% mutate(status = "Exotic")
)


dat.gg <- Lookup.8stands %>%
  mutate(prediction.index = row_number()) %>%
  
  left_join(dat, by = "prediction.index") %>%
  
  mutate(label = sprintf("sm%s-med%s-lg%s", small, medium, large),
         floodgrp = factor(floodgrp))

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0.8

gg <- ggplot(data = dat.gg, aes(x = label, colour = grp, group = floodgrp)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95),
                 position = position_dodge(width = dodgew),
                 size = 0.5) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50), 
                 position = position_dodge(width = dodgew),
                 size = 1.0) +
  
  geom_point(aes(y = mid, shape = floodgrp),
                 position = position_dodge(width = dodgew),
             size = 2.0) +
  
  scale_color_discrete(name = "Varying size classes") +

  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  facet_wrap(~ status, scales = "free_x") +
  
  theme(panel.grid.major.y = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_newsites_richness_nat_ex_flood.pdf", size = pagesize())

print(gg)

```


```{r  fig.width=8, fig.height=10}

dodgew <- 0.4

gg <- ggplot(data = dat.gg, aes(x = label, colour = floodgrp)) +
  geom_linerange(aes(ymin = lwr95, ymax = upr95),
                 position = position_dodge(width = dodgew),
                 size = 0.75) +
  
  geom_linerange(aes(ymin = lwr50, ymax = upr50), 
                 position = position_dodge(width = dodgew),
                 size = 2.5) +
  
  #geom_point(aes(y = mid),
  #               position = position_dodge(width = dodgew),
  #           size = 4.0) +
  
  scale_color_discrete(name = "Flood group") +

  labs(x = "", y = "Predicted number of species",
       title = "Predicted species richness over varying stand configurations",
       subtitle = "Based on probability of occurrence for 95 modelling species") +
  
  coord_flip() + 
  
  facet_wrap(~ status) +
  
  theme(panel.grid.major.y = element_line(colour = "grey70"))


gg_pdf(gg, filename = "model3A_8stands_richness_nat_ex_flood.pdf", size = pagesize())

print(gg)

```


## Model 3B - stem density and flood frequency

### Model code

The code is based on the BORAL-generated JAGS code for model 3 combined with the JAGS code for the stem count model (see `model_subplot_stems_JAGS.Rmd`).

```{r}

model3B.Code <- "model {
  # Model mean stem count by size class within each plot
  # Counts are treated as negative binomial - implemented as
  # Poisson with Gamma-distributed mean
  for (i in 1:length(nstems)) {
    nstems[i] ~ dpois(mu.stems[plot[i], sz[i]] * h[i])
    h[i] ~ dgamma(theta[sz[i]], theta[sz[i]])
  }

  # Priors for stem count model
  for (sz in 1:11) {
    # Estimate dispersion independently for each size class
    theta[sz] ~ dexp(1)

    # Overall mean stems (log scale) for each size class
    logmu.size[sz] ~ dnorm(0, 5)

    sd.size[sz] ~ dunif(0, 5)
    tau.size[sz] <- pow(sd.size[sz], -2)
    
    for (i in 1:66) {
      logmu.stems[i, sz] ~ dnorm(logmu.size[sz], tau.size[sz])
      mu.stems[i, sz] <- exp(logmu.stems[i, sz])
    }
  }
  
  # Aggregate modelled stem counts for field size classes into
  # the broader size classes to which species will be related
  for (i in 1:nplots) {
    for (k in 1:nsizeclasses) {
      X.stems[i, k] <- sum(mu.stems[i, (MinSize[k]):(MaxSize[k])])
    }
  }

  # Model species occurrence
  for(i in 1:nplots) {
    for(j in 1:nspecies) { 
      eta[i,j] <- inprod(lv.coefs[j,2:(num.lv+1)],lvs[i,]) + 
        row.coefs.ID1[i] + 
        flood.coef[j] * relfloodfreq[i] +
        inprod(stem.coefs[j,], X.stems[i,])
    
      Z[i,j] ~ dnorm(lv.coefs[j,1] + eta[i,j], 1)
      y[i,j] ~ dbern(step(Z[i,j]))

      loglik[(i-1)*(nspecies)+j] <- y[i,j] * log(phi(lv.coefs[j,1] + eta[i,j])) + 
                                 (1 - y[i,j])*log(1 - phi(lv.coefs[j,1] + eta[i,j]))
    }
  }
  
  ## Latent variables ##
  for(i in 1:nplots) { for(k in 1:num.lv) { lvs[i,k] ~ dnorm(0,1) } } 
  
  ## Process level and priors ##
  for(j in 1:nspecies) { lv.coefs[j,1] ~ dnorm(0,0.1) } ## Separate species intercepts
  
  for(i in 1:nplots) { 
    row.coefs.ID1[i] ~ dnorm(0, pow(row.sigma.ID1,-2)) 
  } 
  row.sigma.ID1 ~ dunif(0,30)
  
  for(i in 1:(num.lv-1)) { 
    for(j in (i+2):(num.lv+1)) {
      # Constraints to 0 on upper diagonal
      lv.coefs[i,j] <- 0 
    } 
  }
  
  for(i in 1:num.lv) { 
     # Sign constraints on diagonal elements
    lv.coefs[i,i+1] ~ dnorm(0,0.1)I(0,) 
  }
  
  for(i in 2:num.lv) { 
    for(j in 2:i) { 
      # Free lower diagonals
      lv.coefs[i,j] ~ dnorm(0,0.1) 
    } 
  }
  
  for(i in (num.lv+1):nspecies) { 
    for(j in 2:(num.lv+1)) { 
      # All other elements
      lv.coefs[i,j] ~ dnorm(0,0.1)
    } 
  }
  
  # species coefficients on flood frequency and stem density
  # drawn from Laplace priors with variance equal to that of 
  # the boral default priors (10).

  laplace.scale <- sqrt(2 / 10)
  for(j in 1:nspecies) { 
    # coefficient on flood frequency 
    flood.coef[j] ~ ddexp(0, laplace.scale) 

    for (ksize in 1:nsizeclasses) {
      stem.coefs[j,ksize] ~ ddexp(0, laplace.scale)
    }
  }
}"


```


### Data objects for model

Data are as for model 3B except that flood history of 9ha plots is represented by flood frequency values rather than flood group.

```{r}

# Aggregated size classes for modelling

SizeClasses <- c("less10cm", "from10to20cm", "from20to30cm",
                 "from30to40cm", "from40to80cm", "from80cm")

FieldToModelSizeClass <- list(
  1, 2, 3, 4, 5:8, 9:11
)

# JAGS will not work with the lookup list FieldToModelSizeClass
# directly, so we create vector versions
MinSize <- sapply(FieldToModelSizeClass, min)
MaxSize <- sapply(FieldToModelSizeClass, max)


# Flood data
path <- here("data", "inundation.RData")

# Minimum value of cloud-free cover for a plot necessary to classify 
# an observation as a flood event
MinCloudFree <- 0.25


dat.nfloods <- load_from(path) %>%
  mutate(p.flood = ifelse(prop.cloudfree >= MinCloudFree, prop.inundated, NA) ) %>%
  
  filter(!is.na(p.flood), p.flood > 0) %>%
  
  group_by(site, plot) %>%
  summarize(N = n()) %>%
  ungroup() %>%
  
  # flood frequency as proportion of max
  mutate(Np = N / max(N)) %>%
  
  select(site, plot, N, Np) %>%
  
  arrange(site, plot)



model3B.data <- list(
  y = M.y,
  relfloodfreq = dat.nfloods$Np,
  nplots = nrow(M.y),
  nspecies = ncol(M.y),
  
  num.lv = 2,
  
  # stem counts
  plot = dat.stems.observed$plot,
  sz = dat.stems.observed$sz,
  nstems = dat.stems.observed$nstems,
  nsizeclasses = length(SizeClasses),
  MinSize = MinSize,
  MaxSize = MaxSize
)

```


### Compile and run the model

```{r}

# Function to generate initial values for Z: matrix of probit values.
# Takes the matrix of sites x species occurrences as an argument.
#
fn_Zinit <- function(y) {
  nc <- ncol(y)
  nr <- nrow(y)
  
  Tau <- rWishart(1, nc + 1, diag(nc))[, , 1]
  Sigma <- solve(Tau)

  Z <- abs(t(mvtnorm::rmvnorm(nr, rep(0, nc), Sigma)))
  Z <- ifelse(as.matrix(y), Z, -1 * Z)
  
  Z
}


Model3B.Path <- here::here("models", "fitted", "model3B_mcmc.RData")

if (REFIT_MODELS || !file.exists(Model3B.Path)) {
  model3B <- R2jags::jags(
    data = model3B.data, 
    inits = list(list(Z = fn_Zinit(M.y))), 
    parameters.to.save = c("flood.coef",
                           "lvs", "lv.coefs", 
                           "mu.stems",
                           "row.coefs.ID1",
                           "row.sigma.ID1",
                           "stem.coefs"), 
    model.file = textConnection(model3B.Code),
    n.chains = 1, 
    n.iter = 110000, 
    n.burnin = 10000, 
    n.thin = 20)
  
  
  model3B.samples <- coda::mcmc(model3B$BUGSoutput$sims.matrix, start = 1, thin = 1)
  save(model3B.samples, file = Model3B.Path)
  
} else {
  model3B.samples <- load_from(Model3B.Path)
}
  
```


Separate posterior samples into those for parameters and those for species x plot log-likelihoods.

```{r}

ii <- str_detect(colnames(model3B.samples), "loglik")
model3B.loglik <- as.matrix( model3B.samples[, ii] )
model3B.samples <- model3B.samples[, !ii]

```


### Check model convergence

Geweke's diagnostic for model convergence.

```{r}

g <- coda::geweke.diag(model3B.samples)
ok <- (2 * pnorm(abs(g$z), lower.tail = FALSE) > 0.05)
p <- sum(ok, na.rm = TRUE) / length(na.omit(ok))

cat(round(p * 100, 2), "percent of parameters converged")

```


Check for parameters with less than 4000 effectively independent samples. Note, parameter lv.coefs[1,3] will always have zero effective samples because its value is fixed at zero in the model.

```{r}

x <- coda::effectiveSize(model3B.samples)
ii <- x < 4000

if (sum(ii) > 1) {
  cat(sum(ii) - 1, "free parameters with less than 4000 samples\n")
  print(x[ii])
} else {
  cat("All free parameters have at least 4000 samples")
}

```


### Model results

#### Species responses to stem density

Here we summarize the modelled relationship between probability of occurrence and stem density for each understorey species. The graph shows median values for species coefficients on tree size classes based on data over all plots. Positive values indicate a higher probability of occurrence and negative values a lower probability.

```{r}

ii <- str_detect(colnames(model3B.samples), "^stem.coefs")

x <- apply(model3B.samples[, ii], MARGIN=2, median)

model3B.stemeffects <- data.frame(
  param = names(x),
  median.value = x,
  stringsAsFactors=FALSE) %>%
  
  mutate(nums = str_extract(param, "\\d+\\,\\d+"),
         spnum = as.integer(str_extract(nums, "^\\d+")),
         sizeclass = as.integer(str_extract(nums, "\\d+$"))) %>%
  
  # Scale coefficient values within each size class to account
  # for the unstandardized stem counts used in the model
  group_by(sizeclass) %>%
  mutate(median.value = scale(median.value)) %>%
  ungroup() %>%
  
  # Add species info
  left_join(SpeciesSubset %>% mutate(spnum = row_number()),
            by = "spnum") %>%
  
  mutate(status = ifelse(is.na(weed), "Indet", ifelse(weed, "Exotic", "Native")),
         group = ifelse(status == "Exotic", "exotic", 
                        ifelse(habitat == "terrestrial", "dry", "wet")) ) %>%

  select(spnum, workingname, status, group, sizeclass, median.value)
  

# Cluster species based on their vectors of sizeclass variable inclusion rates.
# Do this separately for native/dry, native/wet and exotic species
x <- model3B.stemeffects %>%
  tidyr::spread(sizeclass, median.value, sep="_") %>%

  group_by(group) %>%
  do (
    {
      n <- nrow(.)
      d <- dist(.[, paste0("sizeclass_", 1:6)])  # euclidean distance
      h <- hclust(d, method = "complete")
      data.frame(spnum = .$spnum[h$order], rank = 1:n)
    }
  )


dat.gg <- left_join(model3B.stemeffects, x, 
                    by = c("spnum", "group"))

# Record order of species names to use as factor levels for ggplot
levels <- dat.gg %>%
  arrange(group, rank) %>%
  distinct(workingname)

dat.gg <- dat.gg %>%
  mutate(workingname = factor(workingname, levels = levels$workingname),
         group = factor(group, 
                        levels = c("exotic", "dry", "wet"),
                        labels = c("Exotic", "Native dry", "Native damp/wet")))

```


```{r fig.height=12, fig.width=8}

xlabels <- SizeClasses %>%
  str_replace("less", "<") %>%
  str_replace("from", "") %>%
  str_replace("to", "-")

i <- length(xlabels)
xlabels[i] <- paste0(">", xlabels[i])


gg <- ggplot(data = dat.gg) +
  geom_raster(aes(x = sizeclass, y = workingname, fill = median.value)) +
  
  scale_fill_gradient2(name = "Effect",
                       low = "#7b3294", mid = "#fafafa", high = "#008837") +
  
  scale_x_continuous(breaks = 1:6, labels = xlabels) +
  
  labs(x = "Size class", y = "Species",
       title = "Median species coefficients on stem size classes") +
  
  facet_grid(group ~ ., scales = "free_y", space = "free_y")


gg_pdf(plot = gg, 
       file = here("models/outputs/model3B_stem_effects.pdf"), 
       size = pagesize("A3"))

print(gg)

```



#### Predict on training data

```{r}

Model3B.linpred.Path <- here::here("models", "fitted", "model3B_linpred.RData")

if (REFIT_MODELS || !file.exists(Model3B.linpred.Path)) {
  
  nplots <- model3B.data$nplots
  nspecies <- model3B.data$nspecies
  nfloodgrp <- n_distinct(model3B.data$floodgroup)
  nsizeclasses <- model3B.data$nsizeclasses
  
  # Check that we have the correct lookup list for field to
  # model size classes
  stopifnot(length(FieldToModelSizeClass) == nsizeclasses)
  
  niter <- nrow(model3B.samples)
  
  get_indices <- function(ptn, n.expected = NULL) {
    ii <- str_detect(colnames(model3B.samples), ptn)
    if (!is.null(n.expected)) {
      stopifnot(sum(ii) == n.expected)
    }
    ii
  }
  
  ii.lvcoefs <- get_indices("lv.coefs", nspecies * 3)
  ii.stemcoefs <- get_indices("stem.coefs", nspecies * nsizeclasses)
  ii.floodcoefs <- get_indices("flood.coef", nspecies) # 'coef' not 'coefs'
  ii.rowcoefs <- get_indices("row.coefs", nplots)

  ii.lvs <- get_indices("lvs", nplots * 2)
  ii.mu.stems <- get_indices("mu.stems", nplots * 11) # 11 field size classes

  # Vector of relative flood frequencies (proportion of global max value)  
  relfloodfreq <- model3B.data$relfloodfreq

  model3B.linpred <- array(0, dim = c(nplots, nspecies, niter))
  
  for (ipost in 1:niter) {
    # contribution of species intercept and latent variables
    lv.coefs <- matrix(model3B.samples[ipost, ii.lvcoefs], nrow = nspecies)
    lvs <- cbind(1, matrix(model3B.samples[ipost, ii.lvs], nrow = nplots))
    eta <- tcrossprod(lvs, lv.coefs)
    
    # contribution of stem density
    stem.coefs <- matrix(model3B.samples[ipost, ii.stemcoefs], nrow = nspecies)
    mu.stems <- matrix(model3B.samples[ipost, ii.mu.stems], nrow = nplots)
    
    # aggregate modelled field counts to the broader six size classes
    X.stems <- lapply(FieldToModelSizeClass, function(cols) {
      x <- rep(0, nplots)
      for (k in cols) {
        x <- x + mu.stems[,k]
      }
      x
    })
    X.stems <- do.call(cbind, X.stems)
    
    eta <- eta + tcrossprod(X.stems, stem.coefs)
    
    # contribution of flood frequency
    flood.coefs <- model3B.samples[ipost, ii.floodcoefs] # Vector
    eta <- eta + tcrossprod(relfloodfreq, flood.coefs)
    
    # row effects (vector)
    row.coefs <- model3B.samples[ipost, ii.rowcoefs]
    eta <- eta + row.coefs
    
    model3B.linpred[,,ipost] <- eta
  }
  
  save(model3B.linpred, file = Model3B.linpred.Path)
  
} else {
  model3B.linpred <- load_from(Model3B.linpred.Path)
}

```


#### Compare predicted and observed species richness

Sum occurrence probabilities within each plot to arrive at posterior estimates of species richness, and compare to observed values.

```{r}

predicted.richness <- apply(model3B.linpred, MARGIN = 1, 
                            FUN = function(lp) {
                              # lp will have species as rows, samples as cols
                              rich <- colSums(pnorm(lp))
                              q50 <- unname( hpdi(rich, 0.5)[1,] )
                              q95 <- unname( hpdi(rich, 0.95)[1,] )
                              c(q95[1], q50[1], median(rich), q50[2], q95[2])
                            })

predicted.richness <- t(predicted.richness) 
colnames(predicted.richness) <- c("lwr95", "lwr50", "mid", "upr50", "upr95")

dat.gg <- as.data.frame(predicted.richness) %>%
  mutate(plot = row_number(),
         site = 1 + (plot - 1) %/% 3,
         observed = rowSums(model3B.data$y),
         label = ifelse(plot %% 3 == 2, site, ""))

dat.bkg <- dat.gg %>%
  group_by(site) %>%
  summarize(xmin = min(plot) - 0.5, xmax = max(plot) + 0.5) %>%
  ungroup() %>%
  
  mutate(ymin = min(dat.gg$lwr95) - 1, 
         ymax = max(dat.gg$upr95) + 1,
         filled = site %% 2 == 0)

gg <- ggplot(data = dat.gg) +
  geom_rect(data = dat.bkg, 
            aes(xmin = xmin, xmax = xmax, 
                ymin = ymin, ymax = ymax,
                fill = filled),
            show.legend = FALSE) +
  
  scale_fill_manual(values = c("#ffffff00", "#dfdfdfff")) +
  
  geom_linerange(aes(x = plot, ymin = lwr95, ymax = upr95),
                 size = 0.75, colour = "grey50") +
  
  geom_linerange(aes(x = plot, ymin = lwr50, ymax = upr50),
                 size = 2.5, colour = "grey50") +
  
  geom_point(aes(x = plot, y = observed), size = 4) +
  
  scale_x_continuous(breaks = 1:66, labels = dat.gg$label) +
  
  scale_y_continuous(limits = c(9,51)) +
  
  labs(x = "Site", y = "Species richness",
       title = "Comparison of observed and predicted species richness within 9ha plots",
       subtitle = paste("Points are observed values.",
                        "Thick and thin lines are 50% and 95% HPD intervals.")) +
  
  coord_flip() +
  
  theme(axis.ticks.y = element_blank())


gg_pdf(gg, "model3B_postpred_check_richness.pdf", pagesize('A4', 'portrait'))

print(gg)

```


## Compare models

The graphs showing species coefficients on stem density are quite different between the two models. This could be due to the different values of the flood terms between the models, or it could possibly indicate problems with model validity or convergence.


### Check latent variables

```{r}

ii <- str_detect(colnames(model3A.samples), "^lvs")
x <- apply(model3A.samples[, ii], MARGIN = 2, median)
dat1 <- data.frame(model = "3A", 
                   label = names(x),
                   value = x)

ii <- str_detect(colnames(model3B.samples), "^lvs")
x <- apply(model3B.samples[, ii], MARGIN = 2, median)
dat2 <- data.frame(model = "3B",
                   label = names(x),
                   value = x)

dat <- rbind(dat1, dat2) %>%
  mutate(nums = str_extract(label, "[\\d\\,]+"),
         plot = as.integer(str_extract(nums, "^\\d+")),
         lv = as.integer(str_extract(nums, "\\d$"))) %>%
  
  mutate(lv = paste(model, lv, sep = "_")) %>%
  
  select(plot, lv, value) %>%
  
  tidyr::spread(lv, value)

```

```{r}

ggplot(data = dat) +
  geom_segment(aes(x = `3A_1`, y = `3A_2`, xend = `3B_1`, yend = `3B_2`),
               arrow = arrow(length = unit(2, "mm"))) +
  
  labs(x = "LV1", y = "LV2",
       title = "Change in ordination position: model 3A to 3B") +
  
  coord_equal()

```


```{r}

ggplot(data = dat) +
  geom_point(aes(x = `3A_1`, y = `3A_2`, shape="3A")) +
  geom_point(aes(x = `3B_1`, y = `3B_2`, shape = "3B")) +
  
  scale_shape_manual(name = "Model", values = c(1, 16)) +
  
  labs(x = "LV1", y = "LV2",
       title = "Overview of ordination positions") +
  
  coord_equal()
  
```


### Compare models with LOO

**Note: this doesn't work**

The `loo::loo` function complains "Can't fit generalized Pareto distribution because all tail values are the same."

The `loo::waic` function runs but reports that an excessive number of p_waic estimates "greater than 0.4"

```

reff.3A <- loo::relative_eff(model3A.loglik, chain_id = rep(1, nrow(model3A.loglik)))

# Species in all or almost all plots have NA values for reff. Set these to 1.0
ii <- is.na(reff.3A)
reff.3A[ii] <- 1

loo.3A <- loo::loo(model3A.loglik, r_eff = reff.3A)

```

### Compare log-likelihood samples directly

Here we take the matrix of log-likelihood values for model 3A (flood groups) and compare it to the matrix for model 3B (flood frequency) by calculating, for each column (species within plot) the proportion of 3A values that are higher than 3B values.

```{r}

# Compare each posterior sample of log-likelihood for each observation of 
# species at plot and flag as better under model3A or not
#
LL.compare <- model3A.loglik > model3B.loglik

# Calculate, by species, the proportion of samples where model 3A 
# had the higher log-likelihood
#
colnames(LL.compare) <- 1:ncol(LL.compare)

LL.compare <- LL.compare %>%
  as.data.frame() %>%
  
  tidyr::gather(index, value, convert = TRUE) %>%
  
  mutate(plotindex = 1 + ((index - 1) %/% 95), 
         spindex = 1 + ((index - 1) %% 95) ) %>%
  
  group_by(spindex) %>%
  summarize(p3A = mean(value))

# Number of species with higher LL more than half the time
n <- sum(LL.compare$p3A > 0.5)
cat(n, "species have higher LL under model 3A in more than 50% of samples")

```

```{r}

ggplot(data = LL.compare) +
  
  geom_density(aes(x = p3A)) +
  
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  
  labs(x = "Proportion of samples",
       title = "Distribution of per-species model comparison values",
       subtitle = "Values are proportion of MCMC LL samples higher in model3A")

```


List species in descending order of proportion of samples with better log-likelihood values under model3A (flood groups) that under model3B (flood frequency)

```{r}

LL.compare <- bind_cols(LL.compare, SpeciesSubset) %>%
  arrange(desc(p3A)) %>%
  rename(prop.model3A.higher = p3A)

path <- here::here("models", "outputs", "model3A_3B_loglik_comparison.csv")
write.csv(LL.compare, file = path)

```


Is there any relationship between the best model for a species and its occurrence frequency or weed status?

Note that the comparison for species in all or most plots should be disregarded as the log-likelihood values will be almost zero for both models.

```{r}

ggplot(data = LL.compare) + 
  geom_point(aes(x = nplots, y = prop.model3A.higher, colour = weed), 
             size=3, alpha = 0.5) + 
  
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  
  labs(x = "Number of plot occurrences",
       y = "Proportion of samples better under model 3A",
       title = "Model preference for individual species")

```



## Model 3C - stem density and flood groups (four aggregate size classes)

This model is essentially the same as model 3A (above) but rather than estimating counts for the 11 size classes defined in the field data and then aggregating these into broader size classes, we aggregate the input data and model the broader classes directly.

### Model code

```{r}

model3C.Code <- "model {
  # Model mean stem count by model size class within each plot
  # Counts are treated as negative binomial - implemented as
  # Poisson with Gamma-distributed mean
  for (i in 1:length(nstems)) {
    nstems[i] ~ dpois(mu.stems[plot[i], sz[i]] * h[i])
    h[i] ~ dgamma(theta[sz[i]], theta[sz[i]])
  }

  # Priors for stem count model
  for (sz in 1:nsizeclasses) {
    # Estimate dispersion independently for each size class
    theta[sz] ~ dexp(1)

    # Overall mean stems (log scale) for each size class
    logmu.size[sz] ~ dnorm(0, 5)

    sd.size[sz] ~ dunif(0, 5)
    tau.size[sz] <- pow(sd.size[sz], -2)
    
    for (i in 1:66) {
      logmu.stems[i, sz] ~ dnorm(logmu.size[sz], tau.size[sz])
      mu.stems[i, sz] <- exp(logmu.stems[i, sz])
    }
  }
  
  # Model species occurrence
  for(i in 1:nplots) {
    for(j in 1:nspecies) { 
      eta[i,j] <- inprod(lv.coefs[j,2:(num.lv+1)],lvs[i,]) + 
        row.coefs.ID1[i] + 
        flood.coefs[j, floodgroup[i]] +
        inprod(stem.coefs[j,], mu.stems[i,])
    
      Z[i,j] ~ dnorm(lv.coefs[j,1] + eta[i,j], 1)
      y[i,j] ~ dbern(step(Z[i,j]))

      loglik[(i-1)*(nspecies)+j] <- y[i,j] * log(phi(lv.coefs[j,1] + eta[i,j])) + 
                                 (1 - y[i,j])*log(1 - phi(lv.coefs[j,1] + eta[i,j]))
    }
  }
  
  ## Latent variables ##
  for(i in 1:nplots) { for(k in 1:num.lv) { lvs[i,k] ~ dnorm(0,1) } } 
  
  ## Process level and priors ##
  for(j in 1:nspecies) { lv.coefs[j,1] ~ dnorm(0,0.1) } ## Separate species intercepts
  
  for(i in 1:nplots) { 
    row.coefs.ID1[i] ~ dnorm(0, pow(row.sigma.ID1,-2)) 
  } 
  row.sigma.ID1 ~ dunif(0,30)
  
  for(i in 1:(num.lv-1)) { 
    for(j in (i+2):(num.lv+1)) {
      # Constraints to 0 on upper diagonal
      lv.coefs[i,j] <- 0 
    } 
  }
  
  for(i in 1:num.lv) { 
     # Sign constraints on diagonal elements
    lv.coefs[i,i+1] ~ dnorm(0,0.1)I(0,) 
  }
  
  for(i in 2:num.lv) { 
    for(j in 2:i) { 
      # Free lower diagonals
      lv.coefs[i,j] ~ dnorm(0,0.1) 
    } 
  }
  
  for(i in (num.lv+1):nspecies) { 
    for(j in 2:(num.lv+1)) { 
      # All other elements
      lv.coefs[i,j] ~ dnorm(0,0.1)
    } 
  }
  
  # species coefficients on flood group and stem density
  # drawn from Laplace priors with variance equal to that of 
  # the boral default priors (10).

  laplace.scale <- sqrt(2 / 10)
  for(j in 1:nspecies) { 
    # coefficient on flood group
    for (kflood in 1:3) {
      flood.coefs[j, kflood] ~ ddexp(0, laplace.scale) 
    }

    for (ksize in 1:nsizeclasses) {
      stem.coefs[j,ksize] ~ ddexp(0, laplace.scale)
    }
  }
}"

```


### Data objects for model

Here we pre-aggregate the stem counts for eleven field size classes into the four broader size classes to be used for modelling. The first size class (<10cm) was sometimes not recorded for all ten sub-plots within each plot. Luckily, this size class is also one of the modelling size classes, so the model will naturally account for the different sample sizes (8 or 10 sub-plots) across plots.

```{r}

# Aggregated size classes for modelling
SizeClasses <- c("less10cm", "from10to40cm", "from40to80cm", "from80cm")

# Lookup table for field size class => aggregate size class
SizeClassLookup <- data.frame(
  fieldsz = 1:11,
  modelsz = c(1,2,2,2,3,3,3,3,4,4,4)
)

# Stem data
stems.dir <- here::here("..", "red_gum_thinning", "stem_densities")

path <- file.path(stems.dir, "data", "stems_complete.RData")

dat.stems.observed.agg <- load_from(path) %>%
  # Subset to control and pre-thinning plot data
  filter(survey %in% c("control", "pre.thinning")) %>%
  
  arrange(site, plot, subplot) %>%
  
  select(site, plot, subplot, !!(SIZES$sizeclass)) %>%
  
  tidyr::gather(sizeclass, nstems, -c(site, plot, subplot)) %>%
  
  filter(!is.na(nstems)) %>%
  
  mutate(sz = match(sizeclass, SIZES$sizeclass)) %>%
  
  # Aggregate classes, keeping sub-plot counts separate
  left_join(SizeClassLookup, by = c("sz" = "fieldsz")) %>%
  
  group_by(site, plot, subplot, modelsz) %>%
  summarize(nstems = sum(nstems)) %>%
  ungroup() %>%
  
  mutate(plotindex = 3*(site-1) + plot) %>%
  select(plotindex, modelsz, nstems)
  

model3C.data <- list(
  y = M.y,
  floodgroup = as.integer(SiteLookup$floodgroup),
  nplots = nrow(M.y),
  nspecies = ncol(M.y),
  
  num.lv = 2,
  
  # stem counts
  plot = dat.stems.observed.agg$plotindex,
  sz = dat.stems.observed.agg$modelsz,
  nstems = dat.stems.observed.agg$nstems,
  nsizeclasses = length(SizeClasses)
)

```


### Compile and run the model

```{r}

# Function to generate initial values for Z: matrix of probit values.
# Takes the matrix of sites x species occurrences as an argument.
#
fn_Zinit <- function(y) {
  nc <- ncol(y)
  nr <- nrow(y)
  
  Tau <- rWishart(1, nc + 1, diag(nc))[, , 1]
  Sigma <- solve(Tau)

  Z <- abs(t(mvtnorm::rmvnorm(nr, rep(0, nc), Sigma)))
  Z <- ifelse(as.matrix(y), Z, -1 * Z)
  
  Z
}


Model3C.Path <- here::here("models", "fitted", "model3C_mcmc.RData")

if (REFIT_MODELS || !file.exists(Model3C.Path)) {
  model3C <- R2jags::jags(
    data = model3C.data, 
    inits = list(list(Z = fn_Zinit(M.y))), 
    parameters.to.save = c("flood.coefs",
                           "loglik",
                           "lvs", "lv.coefs", 
                           "mu.stems",
                           "row.coefs.ID1",
                           "row.sigma.ID1",
                           "stem.coefs"), 
    model.file = textConnection(model3C.Code),
    n.chains = 1, 
    n.iter = 110000, 
    n.burnin = 10000, 
    n.thin = 20)
  
  
  model3C.samples <- coda::mcmc(model3C$BUGSoutput$sims.matrix, start = 1, thin = 1)
  save(model3C.samples, file = Model3C.Path)
  
} else {
  model3C.samples <- load_from(Model3C.Path)
}
  
```


Separate posterior samples into those for parameters and those for species x plot log-likelihoods.

```{r}

ii <- str_detect(colnames(model3C.samples), "loglik")
model3C.loglik <- as.matrix( model3C.samples[, ii] )
model3C.samples <- model3C.samples[, !ii]

```


### Check model convergence for parameters

Geweke's diagnostic for model convergence.

```{r}

g <- coda::geweke.diag(model3C.samples)
ok <- (2 * pnorm(abs(g$z), lower.tail = FALSE) > 0.05)
p <- sum(ok, na.rm = TRUE) / length(na.omit(ok))

cat(round(p * 100, 2), "percent of parameters converged")

```

Manual inspection of sample traces for the parameters that did not satisfy the Geweke test suggested that they had converged.


Check for parameters with less than 4000 effectively independent samples. Note, parameter lv.coefs[1,3] will always have zero effective samples because its value is fixed at zero in the model.

```{r}

x <- coda::effectiveSize(model3C.samples)
ii <- x < 4000

if (sum(ii) > 1) {
  cat(sum(ii) - 1, "free parameters with less than 4000 samples\n")
  print(x[ii])
} else {
  cat("All free parameters have at least 4000 samples")
}

```

Convert posterior samples to a plain matrix.

```{r}

model3C.samples <- as.matrix(model3C.samples)

```


### Model results and predictions

#### Predict on training data

```{r}

Model3C.linpred.Path <- here::here("models", "fitted", "model3C_linpred.RData")

if (REFIT_MODELS || !file.exists(Model3C.linpred.Path)) {
  
  nplots <- model3C.data$nplots
  nspecies <- model3C.data$nspecies
  nfloodgrp <- n_distinct(model3C.data$floodgroup)
  nsizeclasses <- model3C.data$nsizeclasses
  
  niter <- nrow(model3C.samples)
  
  get_indices <- function(ptn, n.expected = NULL) {
    ii <- str_detect(colnames(model3C.samples), ptn)
    if (!is.null(n.expected)) {
      stopifnot(sum(ii) == n.expected)
    }
    ii
  }
  
  ii.lvcoefs <- get_indices("lv.coefs", nspecies * 3)
  ii.stemcoefs <- get_indices("stem.coefs", nspecies * nsizeclasses)
  ii.floodcoefs <- get_indices("flood.coefs", nspecies * nfloodgrp)
  ii.rowcoefs <- get_indices("row.coefs", nplots)

  ii.lvs <- get_indices("lvs", nplots * 2)
  ii.mu.stems <- get_indices("mu.stems", nplots * nsizeclasses)
  
  m.floodgroup <- matrix(0, nrow = nplots, ncol = nfloodgrp)
  ii <- cbind(1:nplots, model3C.data$floodgroup)
  m.floodgroup[ii] <- 1
  
  model3C.linpred <- array(0, dim = c(nplots, nspecies, niter))
  
  for (ipost in 1:niter) {
    # contribution of species intercept and latent variables
    lv.coefs <- matrix(model3C.samples[ipost, ii.lvcoefs], nrow = nspecies)
    lvs <- cbind(1, matrix(model3C.samples[ipost, ii.lvs], nrow = nplots))
    eta <- tcrossprod(lvs, lv.coefs)
    
    # contribution of stem density
    stem.coefs <- matrix(model3C.samples[ipost, ii.stemcoefs], nrow = nspecies)
    mu.stems <- matrix(model3C.samples[ipost, ii.mu.stems], nrow = nplots)
    eta <- eta + tcrossprod(mu.stems, stem.coefs)
    
    # contribution of flood group
    flood.coefs <- matrix(model3C.samples[ipost, ii.floodcoefs], nrow = nspecies)
    eta <- eta + tcrossprod(m.floodgroup, flood.coefs)
    
    # row effects (vector)
    row.coefs <- model3C.samples[ipost, ii.rowcoefs]
    eta <- eta + row.coefs
    
    model3C.linpred[,,ipost] <- eta
  }
  
  save(model3C.linpred, file = Model3C.linpred.Path)
  
} else {
  model3C.linpred <- load_from(Model3C.linpred.Path)
}

```


#### Compare predicted and observed species richness

Sum occurrence probabilities within each plot to arrive at posterior estimates of species richness, and compare to observed values.

```{r}

predicted.richness <- apply(model3C.linpred, MARGIN = 1, 
                            FUN = function(lp) {
                              # lp will have species as rows, samples as cols
                              rich <- colSums(pnorm(lp))
                              q50 <- unname( hpdi(rich, 0.5)[1,] )
                              q95 <- unname( hpdi(rich, 0.95)[1,] )
                              c(q95[1], q50[1], median(rich), q50[2], q95[2])
                            })

predicted.richness <- t(predicted.richness) 
colnames(predicted.richness) <- c("lwr95", "lwr50", "mid", "upr50", "upr95")

dat.gg <- as.data.frame(predicted.richness) %>%
  mutate(plot = row_number(),
         site = 1 + (plot - 1) %/% 3,
         observed = rowSums(model3C.data$y),
         label = ifelse(plot %% 3 == 2, site, ""))

dat.bkg <- dat.gg %>%
  group_by(site) %>%
  summarize(xmin = min(plot) - 0.5, xmax = max(plot) + 0.5) %>%
  ungroup() %>%
  
  mutate(ymin = min(dat.gg$lwr95) - 1, 
         ymax = max(dat.gg$upr95) + 1,
         filled = site %% 2 == 0)


gg <- ggplot(data = dat.gg) +
  geom_rect(data = dat.bkg, 
            aes(xmin = xmin, xmax = xmax, 
                ymin = ymin, ymax = ymax,
                fill = filled),
            show.legend = FALSE) +
  
  scale_fill_manual(values = c("#ffffff00", "#dfdfdfff")) +
  
  geom_linerange(aes(x = plot, ymin = lwr95, ymax = upr95),
                 size = 0.75, colour = "grey50") +
  
  geom_linerange(aes(x = plot, ymin = lwr50, ymax = upr50),
                 size = 2.5, colour = "grey50") +
  
  geom_point(aes(x = plot, y = observed), size = 4) +
  
  scale_x_continuous(breaks = 1:66, labels = dat.gg$label) +
  
  scale_y_continuous(limits = c(9,51)) +
  
  labs(x = "Site", y = "Species richness",
       title = "Comparison of observed and predicted species richness within 9ha plots",
       subtitle = paste("Points are observed values.",
                        "Thick and thin lines are 50% and 95% HPD intervals.")) +
  
  coord_flip() +
  
  theme(axis.ticks.y = element_blank())


gg_pdf(gg, "model3C_postpred_check_richness.pdf", pagesize('A4', 'portrait'))

print(gg)

```

The fit is somewhat poorer than that for model 3A, with slightly wider bounds but less success in capturing the observed values. This could be due to the different approach (modelling pre-aggregating stem counts rather than aggregating modelled counts in 3A) or it might indicate that the four broader size classes are not as good a basis for prediction as the six size classes used in model 3A.

To try to tease this out, we will fit yet another model using pre-aggregated counts for six size classes.


## Model 3D - stem density and flood groups (six aggregate size classes)

### Model code

Since the number of size classes is a parameter, the model code is the same as for 3C.

```{r}

model3D.Code <- model3C.Code

```


### Data objects for model

Here we pre-aggregate the stem counts for eleven field size classes into the six broader size classes to be used for modelling. The first size class (<10cm) was sometimes not recorded for all ten sub-plots within each plot. Luckily, this size class is also one of the modelling size classes, so the model will naturally account for the different sample sizes (8 or 10 sub-plots) across plots.

```{r}

# Aggregated size classes for modelling
SizeClasses <- c("less10cm", "from10to20cm", "from20to30cm",
                 "from30to40cm", "from40to80cm", "from80cm")

# Lookup table for field size class => aggregate size class
SizeClassLookup <- data.frame(
  fieldsz = 1:11,
  modelsz = c(1,2,3,4,5,5,5,5,6,6,6)
)

# Stem data
stems.dir <- here::here("..", "red_gum_thinning", "stem_densities")

path <- file.path(stems.dir, "data", "stems_complete.RData")

dat.stems.observed.agg <- load_from(path) %>%
  # Subset to control and pre-thinning plot data
  filter(survey %in% c("control", "pre.thinning")) %>%
  
  arrange(site, plot, subplot) %>%
  
  select(site, plot, subplot, !!(SIZES$sizeclass)) %>%
  
  tidyr::gather(sizeclass, nstems, -c(site, plot, subplot)) %>%
  
  filter(!is.na(nstems)) %>%
  
  mutate(sz = match(sizeclass, SIZES$sizeclass)) %>%
  
  # Aggregate classes, keeping sub-plot counts separate
  left_join(SizeClassLookup, by = c("sz" = "fieldsz")) %>%
  
  group_by(site, plot, subplot, modelsz) %>%
  summarize(nstems = sum(nstems)) %>%
  ungroup() %>%
  
  mutate(plotindex = 3*(site-1) + plot) %>%
  select(plotindex, modelsz, nstems)
  

model3D.data <- list(
  y = M.y,
  floodgroup = as.integer(SiteLookup$floodgroup),
  nplots = nrow(M.y),
  nspecies = ncol(M.y),
  
  num.lv = 2,
  
  # stem counts
  nsizeclasses = length(SizeClasses),
  plot = dat.stems.observed.agg$plotindex,
  sz = dat.stems.observed.agg$modelsz,
  nstems = dat.stems.observed.agg$nstems
)

```


### Compile and run the model

```{r}

# Function to generate initial values for Z: matrix of probit values.
# Takes the matrix of sites x species occurrences as an argument.
#
fn_Zinit <- function(y) {
  nc <- ncol(y)
  nr <- nrow(y)
  
  Tau <- rWishart(1, nc + 1, diag(nc))[, , 1]
  Sigma <- solve(Tau)

  Z <- abs(t(mvtnorm::rmvnorm(nr, rep(0, nc), Sigma)))
  Z <- ifelse(as.matrix(y), Z, -1 * Z)
  
  Z
}


Model3D.Path <- here::here("models", "fitted", "model3D_mcmc.RData")

if (REFIT_MODELS || !file.exists(Model3D.Path)) {
  model3D <- R2jags::jags(
    data = model3D.data, 
    inits = list(list(Z = fn_Zinit(M.y))), 
    parameters.to.save = c("flood.coefs",
                           "loglik",
                           "lvs", "lv.coefs", 
                           "mu.stems",
                           "row.coefs.ID1",
                           "row.sigma.ID1",
                           "stem.coefs"), 
    model.file = textConnection(model3D.Code),
    n.chains = 1, 
    n.iter = 110000, 
    n.burnin = 10000, 
    n.thin = 20)
  
  
  model3D.samples <- coda::mcmc(model3D$BUGSoutput$sims.matrix, start = 1, thin = 1)
  save(model3D.samples, file = Model3D.Path)
  
} else {
  model3D.samples <- load_from(Model3D.Path)
}
  
```


Separate posterior samples into those for parameters and those for species x plot log-likelihoods.

```{r}

ii <- str_detect(colnames(model3D.samples), "loglik")
model3D.loglik <- as.matrix( model3D.samples[, ii] )
model3D.samples <- model3D.samples[, !ii]

```


### Check model convergence for parameters

Geweke's diagnostic for model convergence.

```{r}

g <- coda::geweke.diag(model3D.samples)
ok <- (2 * pnorm(abs(g$z), lower.tail = FALSE) > 0.05)
p <- sum(ok, na.rm = TRUE) / length(na.omit(ok))

cat(round(p * 100, 2), "percent of parameters converged")

```

Manual inspection of sample traces for the parameters that did not satisfy the Geweke test suggested that they had converged.


Check for parameters with less than 4000 effectively independent samples. Note, parameter lv.coefs[1,3] will always have zero effective samples because its value is fixed at zero in the model.

```{r}

x <- coda::effectiveSize(model3D.samples)
ii <- x < 4000

if (sum(ii) > 1) {
  cat(sum(ii) - 1, "free parameters with less than 4000 samples\n")
  print(x[ii])
} else {
  cat("All free parameters have at least 4000 samples")
}

```

Convert posterior samples to a plain matrix.

```{r}

model3D.samples <- as.matrix(model3D.samples)

```


### Model results and predictions

#### Predict on training data

```{r}

Model3D.linpred.Path <- here::here("models", "fitted", "model3D_linpred.RData")

if (REFIT_MODELS || !file.exists(Model3D.linpred.Path)) {
  
  nplots <- model3D.data$nplots
  nspecies <- model3D.data$nspecies
  nfloodgrp <- n_distinct(model3D.data$floodgroup)
  nsizeclasses <- model3D.data$nsizeclasses
  
  niter <- nrow(model3D.samples)
  
  get_indices <- function(ptn, n.expected = NULL) {
    ii <- str_detect(colnames(model3D.samples), ptn)
    if (!is.null(n.expected)) {
      stopifnot(sum(ii) == n.expected)
    }
    ii
  }
  
  ii.lvcoefs <- get_indices("lv.coefs", nspecies * 3)
  ii.stemcoefs <- get_indices("stem.coefs", nspecies * nsizeclasses)
  ii.floodcoefs <- get_indices("flood.coefs", nspecies * nfloodgrp)
  ii.rowcoefs <- get_indices("row.coefs", nplots)

  ii.lvs <- get_indices("lvs", nplots * 2)
  ii.mu.stems <- get_indices("mu.stems", nplots * nsizeclasses)
  
  m.floodgroup <- matrix(0, nrow = nplots, ncol = nfloodgrp)
  ii <- cbind(1:nplots, model3D.data$floodgroup)
  m.floodgroup[ii] <- 1
  
  model3D.linpred <- array(0, dim = c(nplots, nspecies, niter))
  
  for (ipost in 1:niter) {
    # contribution of species intercept and latent variables
    lv.coefs <- matrix(model3D.samples[ipost, ii.lvcoefs], nrow = nspecies)
    lvs <- cbind(1, matrix(model3D.samples[ipost, ii.lvs], nrow = nplots))
    eta <- tcrossprod(lvs, lv.coefs)
    
    # contribution of stem density
    stem.coefs <- matrix(model3D.samples[ipost, ii.stemcoefs], nrow = nspecies)
    mu.stems <- matrix(model3D.samples[ipost, ii.mu.stems], nrow = nplots)
    eta <- eta + tcrossprod(mu.stems, stem.coefs)
    
    # contribution of flood group
    flood.coefs <- matrix(model3D.samples[ipost, ii.floodcoefs], nrow = nspecies)
    eta <- eta + tcrossprod(m.floodgroup, flood.coefs)
    
    # row effects (vector)
    row.coefs <- model3D.samples[ipost, ii.rowcoefs]
    eta <- eta + row.coefs
    
    model3D.linpred[,,ipost] <- eta
  }
  
  save(model3D.linpred, file = Model3D.linpred.Path)
  
} else {
  model3D.linpred <- load_from(Model3D.linpred.Path)
}

```


#### Compare predicted and observed species richness

Sum occurrence probabilities within each plot to arrive at posterior estimates of species richness, and compare to observed values.

```{r}

predicted.richness <- apply(model3D.linpred, MARGIN = 1, 
                            FUN = function(lp) {
                              # lp will have species as rows, samples as cols
                              rich <- colSums(pnorm(lp))
                              q50 <- unname( hpdi(rich, 0.5)[1,] )
                              q95 <- unname( hpdi(rich, 0.95)[1,] )
                              c(q95[1], q50[1], median(rich), q50[2], q95[2])
                            })

predicted.richness <- t(predicted.richness) 
colnames(predicted.richness) <- c("lwr95", "lwr50", "mid", "upr50", "upr95")

dat.gg <- as.data.frame(predicted.richness) %>%
  mutate(plot = row_number(),
         site = 1 + (plot - 1) %/% 3,
         observed = rowSums(model3D.data$y),
         label = ifelse(plot %% 3 == 2, site, ""))

dat.bkg <- dat.gg %>%
  group_by(site) %>%
  summarize(xmin = min(plot) - 0.5, xmax = max(plot) + 0.5) %>%
  ungroup() %>%
  
  mutate(ymin = min(dat.gg$lwr95) - 1, 
         ymax = max(dat.gg$upr95) + 1,
         filled = site %% 2 == 0)


gg <- ggplot(data = dat.gg) +
  geom_rect(data = dat.bkg, 
            aes(xmin = xmin, xmax = xmax, 
                ymin = ymin, ymax = ymax,
                fill = filled),
            show.legend = FALSE) +
  
  scale_fill_manual(values = c("#ffffff00", "#dfdfdfff")) +
  
  geom_linerange(aes(x = plot, ymin = lwr95, ymax = upr95),
                 size = 0.75, colour = "grey50") +
  
  geom_linerange(aes(x = plot, ymin = lwr50, ymax = upr50),
                 size = 2.5, colour = "grey50") +
  
  geom_point(aes(x = plot, y = observed), size = 4) +
  
  scale_x_continuous(breaks = 1:66, labels = dat.gg$label) +
  
  scale_y_continuous(limits = c(9,51)) +
  
  labs(x = "Site", y = "Species richness",
       title = "Comparison of observed and predicted species richness within 9ha plots",
       subtitle = paste("Points are observed values.",
                        "Thick and thin lines are 50% and 95% HPD intervals.")) +
  
  coord_flip() +
  
  theme(axis.ticks.y = element_blank())


gg_pdf(gg, "model3D_postpred_check_richness.pdf", pagesize('A4', 'portrait'))

print(gg)

```

There is a better fit between predicted and observed richness values with this model than there was with model 3C (four size classes). The model convergence diagnostics were also better, suggesting that the signal were clearer perhaps. 

Interestingly (or frustratingly) it is still not quite as good as the fit between predicted and observed richness seen with model 3A (six size classes aggregated within the model). This is the opposite of what I (MB) expected - c'est la vie.


## Model 3E: stem density and flood groups (four size classes)

This is the final combination: modelling counts for field classes as in model 3A, then aggregating the estimates into the four size classes used with model 3C.

### Model code

The code is the same as model 3A - only the number of size classes has changed.


```{r}

model3E.Code <- model3A.Code

```


### Data objects for model

```{r}

SizeClasses <- c("less10cm", "from10to40cm", "from40to80cm", "from80cm")

FieldToModelSizeClass <- list(
  1, 2:4, 5:8, 9:11
)

# JAGS will not work with the lookup list FieldToModelSizeClass
# directly, so we create vector versions
MinSize <- sapply(FieldToModelSizeClass, min)
MaxSize <- sapply(FieldToModelSizeClass, max)


# Stem data
stems.dir <- here::here("..", "red_gum_thinning", "stem_densities")

dat.stems.observed <- load_from(file.path(stems.dir, "data", "stems_complete.RData")) %>%
  # Subset to control and pre-thinning plot data
  filter(survey %in% c("control", "pre.thinning")) %>%
  
  arrange(site, plot, subplot) %>%
  
  select(site, plot, !!(SIZES$sizeclass)) %>%
  
  tidyr::gather(sizeclass, nstems, -c(site, plot)) %>%
  
  filter(!is.na(nstems)) %>%
  
  mutate(plotindex = 3*(site-1) + plot,
         sz = match(sizeclass, SIZES$sizeclass)) %>%
  
  select(plot = plotindex, sz, nstems)



model3E.data <- list(
  y = M.y,
  floodgroup = as.integer(SiteLookup$floodgroup),
  nplots = nrow(M.y),
  nspecies = ncol(M.y),
  
  num.lv = 2,
  
  # stem counts
  plot = dat.stems.observed$plot,
  sz = dat.stems.observed$sz,
  nstems = dat.stems.observed$nstems,
  nsizeclasses = length(SizeClasses),
  MinSize = MinSize,
  MaxSize = MaxSize
)

```


### Compile and run the model

```{r}

# Function to generate initial values for Z: matrix of probit values.
# Takes the matrix of sites x species occurrences as an argument.
#
fn_Zinit <- function(y) {
  nc <- ncol(y)
  nr <- nrow(y)
  
  Tau <- rWishart(1, nc + 1, diag(nc))[, , 1]
  Sigma <- solve(Tau)

  Z <- abs(t(mvtnorm::rmvnorm(nr, rep(0, nc), Sigma)))
  Z <- ifelse(as.matrix(y), Z, -1 * Z)
  
  Z
}


Model3E.Path <- here::here("models", "fitted", "model3E_mcmc.RData")

if (REFIT_MODELS || !file.exists(Model3E.Path)) {
  model3E <- R2jags::jags(
    data = model3E.data, 
    inits = list(list(Z = fn_Zinit(M.y))), 
    parameters.to.save = c("flood.coefs",
                           "loglik",
                           "lvs", "lv.coefs", 
                           "mu.stems",
                           "row.coefs.ID1",
                           "row.sigma.ID1",
                           "stem.coefs"), 
    model.file = textConnection(model3E.Code),
    n.chains = 1, 
    n.iter = 210000, 
    n.burnin = 10000, 
    n.thin = 20)
  
  
  model3E.samples <- coda::mcmc(model3E$BUGSoutput$sims.matrix, start = 1, thin = 1)
  save(model3E.samples, file = Model3E.Path)
  
} else {
  model3E.samples <- load_from(Model3E.Path)
}
  
```


Separate posterior samples into those for parameters and those for species x plot log-likelihoods.

```{r}

ii <- str_detect(colnames(model3E.samples), "loglik")
model3E.loglik <- as.matrix( model3E.samples[, ii] )
model3E.samples <- model3E.samples[, !ii]

```


### Check model convergence for parameters

Geweke's diagnostic for model convergence.

```{r}

g <- coda::geweke.diag(model3E.samples)
ok <- (2 * pnorm(abs(g$z), lower.tail = FALSE) > 0.05)
p <- sum(ok, na.rm = TRUE) / length(na.omit(ok))

cat(round(p * 100, 2), "percent of parameters converged")

```

Manual inspection of sample traces for the parameters that did not satisfy the Geweke test suggested that they had converged.


Check for parameters with less than 4000 effectively independent samples. Note, parameter lv.coefs[1,3] will always have zero effective samples because its value is fixed at zero in the model.

```{r}

x <- coda::effectiveSize(model3E.samples)
ii <- x < 4000

if (sum(ii) > 1) {
  cat(sum(ii) - 1, "free parameters with less than 4000 samples\n")
  print(x[ii])
} else {
  cat("All free parameters have at least 4000 samples")
}

```

Convert posterior samples to a plain matrix.

```{r}

model3E.samples <- as.matrix(model3E.samples)

```


#### Predict on training data

```{r}

Model3E.linpred.Path <- here::here("models", "fitted", "model3E_linpred.RData")

if (REFIT_MODELS || !file.exists(Model3E.linpred.Path)) {
  
  nplots <- model3E.data$nplots
  nspecies <- model3E.data$nspecies
  nfloodgrp <- n_distinct(model3E.data$floodgroup)
  nsizeclasses <- model3E.data$nsizeclasses
  
  # Check that we have the correct lookup list for field to
  # model size classes
  stopifnot(length(FieldToModelSizeClass) == nsizeclasses)
  
  niter <- nrow(model3E.samples)
  
  get_indices <- function(ptn, n.expected = NULL) {
    ii <- str_detect(colnames(model3E.samples), ptn)
    if (!is.null(n.expected)) {
      stopifnot(sum(ii) == n.expected)
    }
    ii
  }
  
  ii.lvcoefs <- get_indices("lv.coefs", nspecies * 3)
  ii.stemcoefs <- get_indices("stem.coefs", nspecies * nsizeclasses)
  ii.floodcoefs <- get_indices("flood.coefs", nspecies * nfloodgrp)
  ii.rowcoefs <- get_indices("row.coefs", nplots)

  ii.lvs <- get_indices("lvs", nplots * 2)
  ii.mu.stems <- get_indices("mu.stems", nplots * 11) # 11 field size classes
  
  m.floodgroup <- matrix(0, nrow = nplots, ncol = nfloodgrp)
  ii <- cbind(1:nplots, model3E.data$floodgroup)
  m.floodgroup[ii] <- 1
  
  model3E.linpred <- array(0, dim = c(nplots, nspecies, niter))
  
  for (ipost in 1:niter) {
    # contribution of species intercept and latent variables
    lv.coefs <- matrix(model3E.samples[ipost, ii.lvcoefs], nrow = nspecies)
    lvs <- cbind(1, matrix(model3E.samples[ipost, ii.lvs], nrow = nplots))
    eta <- tcrossprod(lvs, lv.coefs)
    
    # contribution of stem density
    stem.coefs <- matrix(model3E.samples[ipost, ii.stemcoefs], nrow = nspecies)
    mu.stems <- matrix(model3E.samples[ipost, ii.mu.stems], nrow = nplots)
    
    # aggregate modelled field counts to the broader six size classes
    X.stems <- lapply(FieldToModelSizeClass, function(cols) {
      x <- rep(0, nplots)
      for (k in cols) {
        x <- x + mu.stems[,k]
      }
      x
    })
    X.stems <- do.call(cbind, X.stems)
    
    eta <- eta + tcrossprod(X.stems, stem.coefs)
    
    # contribution of flood group
    flood.coefs <- matrix(model3E.samples[ipost, ii.floodcoefs], nrow = nspecies)
    eta <- eta + tcrossprod(m.floodgroup, flood.coefs)
    
    # row effects (vector)
    row.coefs <- model3E.samples[ipost, ii.rowcoefs]
    eta <- eta + row.coefs
    
    model3E.linpred[,,ipost] <- eta
  }
  
  save(model3E.linpred, file = Model3E.linpred.Path)
  
} else {
  model3E.linpred <- load_from(Model3E.linpred.Path)
}

```


#### Compare predicted and observed species richness

Sum occurrence probabilities within each plot to arrive at posterior estimates of species richness, and compare to observed values.

```{r}

predicted.richness <- apply(model3E.linpred, MARGIN = 1, 
                            FUN = function(lp) {
                              # lp will have species as rows, samples as cols
                              rich <- colSums(pnorm(lp))
                              q50 <- unname( hpdi(rich, 0.5)[1,] )
                              q95 <- unname( hpdi(rich, 0.95)[1,] )
                              c(q95[1], q50[1], median(rich), q50[2], q95[2])
                            })

predicted.richness <- t(predicted.richness) 
colnames(predicted.richness) <- c("lwr95", "lwr50", "mid", "upr50", "upr95")

dat.gg <- as.data.frame(predicted.richness) %>%
  mutate(plot = row_number(),
         site = 1 + (plot - 1) %/% 3,
         observed = rowSums(model3E.data$y),
         label = ifelse(plot %% 3 == 2, site, ""))

dat.bkg <- dat.gg %>%
  group_by(site) %>%
  summarize(xmin = min(plot) - 0.5, xmax = max(plot) + 0.5) %>%
  ungroup() %>%
  
  mutate(ymin = min(dat.gg$lwr95) - 1, 
         ymax = max(dat.gg$upr95) + 1,
         filled = site %% 2 == 0)

gg <- ggplot(data = dat.gg) +
  geom_rect(data = dat.bkg, 
            aes(xmin = xmin, xmax = xmax, 
                ymin = ymin, ymax = ymax,
                fill = filled),
            show.legend = FALSE) +
  
  scale_fill_manual(values = c("#ffffff00", "#dfdfdfff")) +
  
  geom_linerange(aes(x = plot, ymin = lwr95, ymax = upr95),
                 size = 0.75, colour = "grey50") +
  
  geom_linerange(aes(x = plot, ymin = lwr50, ymax = upr50),
                 size = 2.5, colour = "grey50") +
  
  geom_point(aes(x = plot, y = observed), size = 4) +
  
  scale_x_continuous(breaks = 1:66, labels = dat.gg$label) +
  
  scale_y_continuous(limits = c(9,51)) +
  
  labs(x = "Site", y = "Species richness",
       title = "Comparison of observed and predicted species richness within 9ha plots",
       subtitle = paste("Points are observed values.",
                        "Thick and thin lines are 50% and 95% HPD intervals.")) +
  
  coord_flip() +
  
  theme(axis.ticks.y = element_blank())


gg_pdf(gg, "model3E_postpred_check_richness.pdf", pagesize('A4', 'portrait'))

print(gg)

```

